{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/Alejandra119/Criticas_y_Recomendaciones_de_Yelp_y_Google/blob/main/Exploracion_Inicial/Exploracion_Preliminar_Yelp.ipynb","timestamp":1695153999523}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Exploración Preliminar archivos Yelp**"],"metadata":{"id":"GY2ZU3ygmrCs"}},{"cell_type":"markdown","source":["El objetivo de este notebook es poder entender la naturaleza, formato y estructuras que contienen los archivos de Yelp, de tal modo que nos permita posteriormente realizar un proceso de ETL para preparar el datawarehouse. El análisis se realizo en los siguientes archivos:\n","- business.pkl\n","- review.json\n","- user.parquet\n","- checkin.json\n","- tip.json"],"metadata":{"id":"yMXtdgXAnBk1"}},{"cell_type":"markdown","source":["## **Librerias utlizadas**"],"metadata":{"id":"a38ksk0crvlh"}},{"cell_type":"code","source":["#AÑADIR CADA NUEVA LIBRERIA QUE SE UTILICE\n","import pandas as pd\n","import numpy as np\n","import requests\n","import glob\n","import matplotlib.pyplot as plt\n"],"metadata":{"id":"4wbSiaOjr2U_","executionInfo":{"status":"ok","timestamp":1695155557317,"user_tz":240,"elapsed":196,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-fBJ1y6IjlF","outputId":"fc92b3b8-24b3-4bf9-bec9-dcd2f2550961","executionInfo":{"status":"ok","timestamp":1695154509725,"user_tz":240,"elapsed":4152,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## **1. Business**"],"metadata":{"id":"QwsiiXpSoLyC"}},{"cell_type":"code","source":[],"metadata":{"id":"JpFVUb5g2R_K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2. Review**"],"metadata":{"id":"0OQ4J4sKoe_W"}},{"cell_type":"code","source":["!pip install pyspark -v"],"metadata":{"id":"9Fain_K6mqi9","executionInfo":{"status":"ok","timestamp":1695154152039,"user_tz":240,"elapsed":54006,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"0a2d0620-f9b0-4830-96b6-458abd20543d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n","Collecting pyspark\n","  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Running command python setup.py egg_info\n","  /usr/local/lib/python3.10/dist-packages/setuptools/dist.py:755: SetuptoolsDeprecationWarning: Invalid dash-separated options\n","  !!\n","\n","          ********************************************************************************\n","          Usage of dash-separated 'description-file' will not be supported in future\n","          versions. Please use the underscore name 'description_file' instead.\n","\n","          By 2023-Sep-26, you need to update your project and remove deprecated calls\n","          or your builds will no longer be supported.\n","\n","          See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n","          ********************************************************************************\n","\n","  !!\n","    opt = self.warn_dash_deprecation(opt, section)\n","  running egg_info\n","  creating /tmp/pip-pip-egg-info-dvhj_0jj/pyspark.egg-info\n","  writing /tmp/pip-pip-egg-info-dvhj_0jj/pyspark.egg-info/PKG-INFO\n","  writing dependency_links to /tmp/pip-pip-egg-info-dvhj_0jj/pyspark.egg-info/dependency_links.txt\n","  writing requirements to /tmp/pip-pip-egg-info-dvhj_0jj/pyspark.egg-info/requires.txt\n","  writing top-level names to /tmp/pip-pip-egg-info-dvhj_0jj/pyspark.egg-info/top_level.txt\n","  writing manifest file '/tmp/pip-pip-egg-info-dvhj_0jj/pyspark.egg-info/SOURCES.txt'\n","  reading manifest file '/tmp/pip-pip-egg-info-dvhj_0jj/pyspark.egg-info/SOURCES.txt'\n","  reading manifest template 'MANIFEST.in'\n","  warning: no previously-included files matching '*.py[cod]' found anywhere in distribution\n","  warning: no previously-included files matching '__pycache__' found anywhere in distribution\n","  warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n","  writing manifest file '/tmp/pip-pip-egg-info-dvhj_0jj/pyspark.egg-info/SOURCES.txt'\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Running command python setup.py bdist_wheel\n","  /usr/local/lib/python3.10/dist-packages/setuptools/dist.py:755: SetuptoolsDeprecationWarning: Invalid dash-separated options\n","  !!\n","\n","          ********************************************************************************\n","          Usage of dash-separated 'description-file' will not be supported in future\n","          versions. Please use the underscore name 'description_file' instead.\n","\n","          By 2023-Sep-26, you need to update your project and remove deprecated calls\n","          or your builds will no longer be supported.\n","\n","          See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n","          ********************************************************************************\n","\n","  !!\n","    opt = self.warn_dash_deprecation(opt, section)\n","  running bdist_wheel\n","  running build\n","  running build_py\n","  creating build\n","  creating build/lib\n","  creating build/lib/pyspark\n","  copying pyspark/storagelevel.py -> build/lib/pyspark\n","  copying pyspark/instrumentation_utils.py -> build/lib/pyspark\n","  copying pyspark/__init__.py -> build/lib/pyspark\n","  copying pyspark/traceback_utils.py -> build/lib/pyspark\n","  copying pyspark/_globals.py -> build/lib/pyspark\n","  copying pyspark/rdd.py -> build/lib/pyspark\n","  copying pyspark/version.py -> build/lib/pyspark\n","  copying pyspark/statcounter.py -> build/lib/pyspark\n","  copying pyspark/find_spark_home.py -> build/lib/pyspark\n","  copying pyspark/conf.py -> build/lib/pyspark\n","  copying pyspark/shell.py -> build/lib/pyspark\n","  copying pyspark/files.py -> build/lib/pyspark\n","  copying pyspark/status.py -> build/lib/pyspark\n","  copying pyspark/rddsampler.py -> build/lib/pyspark\n","  copying pyspark/profiler.py -> build/lib/pyspark\n","  copying pyspark/broadcast.py -> build/lib/pyspark\n","  copying pyspark/accumulators.py -> build/lib/pyspark\n","  copying pyspark/worker.py -> build/lib/pyspark\n","  copying pyspark/taskcontext.py -> build/lib/pyspark\n","  copying pyspark/java_gateway.py -> build/lib/pyspark\n","  copying pyspark/install.py -> build/lib/pyspark\n","  copying pyspark/serializers.py -> build/lib/pyspark\n","  copying pyspark/shuffle.py -> build/lib/pyspark\n","  copying pyspark/context.py -> build/lib/pyspark\n","  copying pyspark/resultiterable.py -> build/lib/pyspark\n","  copying pyspark/daemon.py -> build/lib/pyspark\n","  copying pyspark/join.py -> build/lib/pyspark\n","  copying pyspark/util.py -> build/lib/pyspark\n","  creating build/lib/pyspark/cloudpickle\n","  copying pyspark/cloudpickle/cloudpickle.py -> build/lib/pyspark/cloudpickle\n","  copying pyspark/cloudpickle/__init__.py -> build/lib/pyspark/cloudpickle\n","  copying pyspark/cloudpickle/cloudpickle_fast.py -> build/lib/pyspark/cloudpickle\n","  copying pyspark/cloudpickle/compat.py -> build/lib/pyspark/cloudpickle\n","  creating build/lib/pyspark/mllib\n","  copying pyspark/mllib/__init__.py -> build/lib/pyspark/mllib\n","  copying pyspark/mllib/common.py -> build/lib/pyspark/mllib\n","  copying pyspark/mllib/feature.py -> build/lib/pyspark/mllib\n","  copying pyspark/mllib/tree.py -> build/lib/pyspark/mllib\n","  copying pyspark/mllib/classification.py -> build/lib/pyspark/mllib\n","  copying pyspark/mllib/regression.py -> build/lib/pyspark/mllib\n","  copying pyspark/mllib/random.py -> build/lib/pyspark/mllib\n","  copying pyspark/mllib/clustering.py -> build/lib/pyspark/mllib\n","  copying pyspark/mllib/recommendation.py -> build/lib/pyspark/mllib\n","  copying pyspark/mllib/evaluation.py -> build/lib/pyspark/mllib\n","  copying pyspark/mllib/fpm.py -> build/lib/pyspark/mllib\n","  copying pyspark/mllib/util.py -> build/lib/pyspark/mllib\n","  creating build/lib/pyspark/mllib/linalg\n","  copying pyspark/mllib/linalg/__init__.py -> build/lib/pyspark/mllib/linalg\n","  copying pyspark/mllib/linalg/distributed.py -> build/lib/pyspark/mllib/linalg\n","  creating build/lib/pyspark/mllib/stat\n","  copying pyspark/mllib/stat/__init__.py -> build/lib/pyspark/mllib/stat\n","  copying pyspark/mllib/stat/distribution.py -> build/lib/pyspark/mllib/stat\n","  copying pyspark/mllib/stat/test.py -> build/lib/pyspark/mllib/stat\n","  copying pyspark/mllib/stat/_statistics.py -> build/lib/pyspark/mllib/stat\n","  copying pyspark/mllib/stat/KernelDensity.py -> build/lib/pyspark/mllib/stat\n","  creating build/lib/pyspark/ml\n","  copying pyspark/ml/model_cache.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/__init__.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/pipeline.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/common.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/wrapper.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/feature.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/tree.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/classification.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/stat.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/regression.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/clustering.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/recommendation.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/evaluation.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/image.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/base.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/fpm.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/functions.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/tuning.py -> build/lib/pyspark/ml\n","  copying pyspark/ml/util.py -> build/lib/pyspark/ml\n","  creating build/lib/pyspark/ml/linalg\n","  copying pyspark/ml/linalg/__init__.py -> build/lib/pyspark/ml/linalg\n","  creating build/lib/pyspark/ml/param\n","  copying pyspark/ml/param/__init__.py -> build/lib/pyspark/ml/param\n","  copying pyspark/ml/param/shared.py -> build/lib/pyspark/ml/param\n","  copying pyspark/ml/param/_shared_params_code_gen.py -> build/lib/pyspark/ml/param\n","  creating build/lib/pyspark/ml/torch\n","  copying pyspark/ml/torch/torch_run_process_wrapper.py -> build/lib/pyspark/ml/torch\n","  copying pyspark/ml/torch/__init__.py -> build/lib/pyspark/ml/torch\n","  copying pyspark/ml/torch/distributor.py -> build/lib/pyspark/ml/torch\n","  copying pyspark/ml/torch/log_communication.py -> build/lib/pyspark/ml/torch\n","  creating build/lib/pyspark/sql\n","  copying pyspark/sql/__init__.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/session.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/group.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/conf.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/observation.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/sql_formatter.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/window.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/utils.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/readwriter.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/dataframe.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/types.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/catalog.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/context.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/functions.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/column.py -> build/lib/pyspark/sql\n","  copying pyspark/sql/udf.py -> build/lib/pyspark/sql\n","  creating build/lib/pyspark/sql/avro\n","  copying pyspark/sql/avro/__init__.py -> build/lib/pyspark/sql/avro\n","  copying pyspark/sql/avro/functions.py -> build/lib/pyspark/sql/avro\n","  creating build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/__init__.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/session.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/client.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/plan.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/group.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/conf.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/expressions.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/window.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/utils.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/readwriter.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/dataframe.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/_typing.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/conversion.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/types.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/catalog.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/functions.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/column.py -> build/lib/pyspark/sql/connect\n","  copying pyspark/sql/connect/udf.py -> build/lib/pyspark/sql/connect\n","  creating build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/__init__.py -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/types_pb2.py -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/base_pb2.py -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/example_plugins_pb2.py -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/expressions_pb2.py -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/common_pb2.py -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/relations_pb2.py -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/catalog_pb2.py -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/base_pb2_grpc.py -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/commands_pb2.py -> build/lib/pyspark/sql/connect/proto\n","  creating build/lib/pyspark/sql/pandas\n","  copying pyspark/sql/pandas/__init__.py -> build/lib/pyspark/sql/pandas\n","  copying pyspark/sql/pandas/map_ops.py -> build/lib/pyspark/sql/pandas\n","  copying pyspark/sql/pandas/utils.py -> build/lib/pyspark/sql/pandas\n","  copying pyspark/sql/pandas/serializers.py -> build/lib/pyspark/sql/pandas\n","  copying pyspark/sql/pandas/conversion.py -> build/lib/pyspark/sql/pandas\n","  copying pyspark/sql/pandas/types.py -> build/lib/pyspark/sql/pandas\n","  copying pyspark/sql/pandas/group_ops.py -> build/lib/pyspark/sql/pandas\n","  copying pyspark/sql/pandas/typehints.py -> build/lib/pyspark/sql/pandas\n","  copying pyspark/sql/pandas/functions.py -> build/lib/pyspark/sql/pandas\n","  creating build/lib/pyspark/sql/protobuf\n","  copying pyspark/sql/protobuf/__init__.py -> build/lib/pyspark/sql/protobuf\n","  copying pyspark/sql/protobuf/functions.py -> build/lib/pyspark/sql/protobuf\n","  creating build/lib/pyspark/sql/streaming\n","  copying pyspark/sql/streaming/__init__.py -> build/lib/pyspark/sql/streaming\n","  copying pyspark/sql/streaming/listener.py -> build/lib/pyspark/sql/streaming\n","  copying pyspark/sql/streaming/state.py -> build/lib/pyspark/sql/streaming\n","  copying pyspark/sql/streaming/readwriter.py -> build/lib/pyspark/sql/streaming\n","  copying pyspark/sql/streaming/query.py -> build/lib/pyspark/sql/streaming\n","  creating build/lib/pyspark/streaming\n","  copying pyspark/streaming/__init__.py -> build/lib/pyspark/streaming\n","  copying pyspark/streaming/kinesis.py -> build/lib/pyspark/streaming\n","  copying pyspark/streaming/listener.py -> build/lib/pyspark/streaming\n","  copying pyspark/streaming/dstream.py -> build/lib/pyspark/streaming\n","  copying pyspark/streaming/context.py -> build/lib/pyspark/streaming\n","  copying pyspark/streaming/util.py -> build/lib/pyspark/streaming\n","  creating build/lib/pyspark/pandas\n","  copying pyspark/pandas/frame.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/__init__.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/exceptions.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/internal.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/supported_api_gen.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/strings.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/namespace.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/mlflow.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/categorical.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/sql_formatter.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/window.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/numpy_compat.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/resample.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/utils.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/extensions.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/_typing.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/generic.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/correlation.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/indexing.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/config.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/groupby.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/base.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/datetimes.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/series.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/accessors.py -> build/lib/pyspark/pandas\n","  copying pyspark/pandas/sql_processor.py -> build/lib/pyspark/pandas\n","  creating build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/__init__.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/date_ops.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/binary_ops.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/boolean_ops.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/string_ops.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/null_ops.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/datetime_ops.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/timedelta_ops.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/categorical_ops.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/base.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/udt_ops.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/complex_ops.py -> build/lib/pyspark/pandas/data_type_ops\n","  copying pyspark/pandas/data_type_ops/num_ops.py -> build/lib/pyspark/pandas/data_type_ops\n","  creating build/lib/pyspark/pandas/indexes\n","  copying pyspark/pandas/indexes/__init__.py -> build/lib/pyspark/pandas/indexes\n","  copying pyspark/pandas/indexes/numeric.py -> build/lib/pyspark/pandas/indexes\n","  copying pyspark/pandas/indexes/category.py -> build/lib/pyspark/pandas/indexes\n","  copying pyspark/pandas/indexes/multi.py -> build/lib/pyspark/pandas/indexes\n","  copying pyspark/pandas/indexes/base.py -> build/lib/pyspark/pandas/indexes\n","  copying pyspark/pandas/indexes/datetimes.py -> build/lib/pyspark/pandas/indexes\n","  copying pyspark/pandas/indexes/timedelta.py -> build/lib/pyspark/pandas/indexes\n","  creating build/lib/pyspark/pandas/missing\n","  copying pyspark/pandas/missing/frame.py -> build/lib/pyspark/pandas/missing\n","  copying pyspark/pandas/missing/__init__.py -> build/lib/pyspark/pandas/missing\n","  copying pyspark/pandas/missing/scalars.py -> build/lib/pyspark/pandas/missing\n","  copying pyspark/pandas/missing/common.py -> build/lib/pyspark/pandas/missing\n","  copying pyspark/pandas/missing/indexes.py -> build/lib/pyspark/pandas/missing\n","  copying pyspark/pandas/missing/general_functions.py -> build/lib/pyspark/pandas/missing\n","  copying pyspark/pandas/missing/window.py -> build/lib/pyspark/pandas/missing\n","  copying pyspark/pandas/missing/resample.py -> build/lib/pyspark/pandas/missing\n","  copying pyspark/pandas/missing/groupby.py -> build/lib/pyspark/pandas/missing\n","  copying pyspark/pandas/missing/series.py -> build/lib/pyspark/pandas/missing\n","  creating build/lib/pyspark/pandas/plot\n","  copying pyspark/pandas/plot/__init__.py -> build/lib/pyspark/pandas/plot\n","  copying pyspark/pandas/plot/core.py -> build/lib/pyspark/pandas/plot\n","  copying pyspark/pandas/plot/plotly.py -> build/lib/pyspark/pandas/plot\n","  copying pyspark/pandas/plot/matplotlib.py -> build/lib/pyspark/pandas/plot\n","  creating build/lib/pyspark/pandas/spark\n","  copying pyspark/pandas/spark/__init__.py -> build/lib/pyspark/pandas/spark\n","  copying pyspark/pandas/spark/utils.py -> build/lib/pyspark/pandas/spark\n","  copying pyspark/pandas/spark/functions.py -> build/lib/pyspark/pandas/spark\n","  copying pyspark/pandas/spark/accessors.py -> build/lib/pyspark/pandas/spark\n","  creating build/lib/pyspark/pandas/typedef\n","  copying pyspark/pandas/typedef/__init__.py -> build/lib/pyspark/pandas/typedef\n","  copying pyspark/pandas/typedef/typehints.py -> build/lib/pyspark/pandas/typedef\n","  creating build/lib/pyspark/pandas/usage_logging\n","  copying pyspark/pandas/usage_logging/__init__.py -> build/lib/pyspark/pandas/usage_logging\n","  copying pyspark/pandas/usage_logging/usage_logger.py -> build/lib/pyspark/pandas/usage_logging\n","  creating build/lib/pyspark/python\n","  creating build/lib/pyspark/python/pyspark\n","  copying pyspark/python/pyspark/shell.py -> build/lib/pyspark/python/pyspark\n","  creating build/lib/pyspark/resource\n","  copying pyspark/resource/information.py -> build/lib/pyspark/resource\n","  copying pyspark/resource/__init__.py -> build/lib/pyspark/resource\n","  copying pyspark/resource/requests.py -> build/lib/pyspark/resource\n","  copying pyspark/resource/profile.py -> build/lib/pyspark/resource\n","  creating build/lib/pyspark/errors\n","  copying pyspark/errors/__init__.py -> build/lib/pyspark/errors\n","  copying pyspark/errors/utils.py -> build/lib/pyspark/errors\n","  copying pyspark/errors/error_classes.py -> build/lib/pyspark/errors\n","  creating build/lib/pyspark/errors/exceptions\n","  copying pyspark/errors/exceptions/__init__.py -> build/lib/pyspark/errors/exceptions\n","  copying pyspark/errors/exceptions/connect.py -> build/lib/pyspark/errors/exceptions\n","  copying pyspark/errors/exceptions/captured.py -> build/lib/pyspark/errors/exceptions\n","  copying pyspark/errors/exceptions/base.py -> build/lib/pyspark/errors/exceptions\n","  creating build/lib/pyspark/examples\n","  creating build/lib/pyspark/examples/src\n","  creating build/lib/pyspark/examples/src/main\n","  creating build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/__init__.py -> build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/logistic_regression.py -> build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/sort.py -> build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/parquet_inputformat.py -> build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/avro_inputformat.py -> build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/transitive_closure.py -> build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/status_api_demo.py -> build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/pi.py -> build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/wordcount.py -> build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/pagerank.py -> build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/kmeans.py -> build/lib/pyspark/examples/src/main/python\n","  copying deps/examples/als.py -> build/lib/pyspark/examples/src/main/python\n","  running egg_info\n","  writing pyspark.egg-info/PKG-INFO\n","  writing dependency_links to pyspark.egg-info/dependency_links.txt\n","  writing requirements to pyspark.egg-info/requires.txt\n","  writing top-level names to pyspark.egg-info/top_level.txt\n","  reading manifest file 'pyspark.egg-info/SOURCES.txt'\n","  reading manifest template 'MANIFEST.in'\n","  warning: no previously-included files matching '*.py[cod]' found anywhere in distribution\n","  warning: no previously-included files matching '__pycache__' found anywhere in distribution\n","  warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n","  writing manifest file 'pyspark.egg-info/SOURCES.txt'\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.data.graphx' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.data.graphx' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.data.graphx' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.data.graphx' to be distributed and are\n","          already explicitly excluding 'pyspark.data.graphx' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.data.mllib' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.data.mllib' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.data.mllib' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.data.mllib' to be distributed and are\n","          already explicitly excluding 'pyspark.data.mllib' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.data.mllib.als' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.data.mllib.als' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.data.mllib.als' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.data.mllib.als' to be distributed and are\n","          already explicitly excluding 'pyspark.data.mllib.als' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.data.mllib.images' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.data.mllib.images' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.data.mllib.images' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.data.mllib.images' to be distributed and are\n","          already explicitly excluding 'pyspark.data.mllib.images' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.data.mllib.images.origin' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.data.mllib.images.origin' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.data.mllib.images.origin' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.data.mllib.images.origin' to be distributed and are\n","          already explicitly excluding 'pyspark.data.mllib.images.origin' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.data.mllib.images.origin.kittens' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.data.mllib.images.origin.kittens' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.data.mllib.images.origin.kittens' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.data.mllib.images.origin.kittens' to be distributed and are\n","          already explicitly excluding 'pyspark.data.mllib.images.origin.kittens' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.data.streaming' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.data.streaming' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.data.streaming' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.data.streaming' to be distributed and are\n","          already explicitly excluding 'pyspark.data.streaming' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.examples.src.main.python.ml' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.examples.src.main.python.ml' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.examples.src.main.python.ml' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.examples.src.main.python.ml' to be distributed and are\n","          already explicitly excluding 'pyspark.examples.src.main.python.ml' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.examples.src.main.python.mllib' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.examples.src.main.python.mllib' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.examples.src.main.python.mllib' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.examples.src.main.python.mllib' to be distributed and are\n","          already explicitly excluding 'pyspark.examples.src.main.python.mllib' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.examples.src.main.python.sql' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.examples.src.main.python.sql' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.examples.src.main.python.sql' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.examples.src.main.python.sql' to be distributed and are\n","          already explicitly excluding 'pyspark.examples.src.main.python.sql' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.examples.src.main.python.sql.streaming' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.examples.src.main.python.sql.streaming' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.examples.src.main.python.sql.streaming' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.examples.src.main.python.sql.streaming' to be distributed and are\n","          already explicitly excluding 'pyspark.examples.src.main.python.sql.streaming' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.examples.src.main.python.streaming' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.examples.src.main.python.streaming' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.examples.src.main.python.streaming' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.examples.src.main.python.streaming' to be distributed and are\n","          already explicitly excluding 'pyspark.examples.src.main.python.streaming' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.sql.pandas._typing' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.sql.pandas._typing' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.sql.pandas._typing' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.sql.pandas._typing' to be distributed and are\n","          already explicitly excluding 'pyspark.sql.pandas._typing' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  /usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'pyspark.sql.pandas._typing.protocols' is absent from the `packages` configuration.\n","  !!\n","\n","          ********************************************************************************\n","          ############################\n","          # Package would be ignored #\n","          ############################\n","          Python recognizes 'pyspark.sql.pandas._typing.protocols' as an importable package[^1],\n","          but it is absent from setuptools' `packages` configuration.\n","\n","          This leads to an ambiguous overall configuration. If you want to distribute this\n","          package, please make sure that 'pyspark.sql.pandas._typing.protocols' is explicitly added\n","          to the `packages` configuration field.\n","\n","          Alternatively, you can also rely on setuptools' discovery methods\n","          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","          instead of `find_packages(...)`/`find:`).\n","\n","          You can read more about \"package discovery\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","          If you don't want 'pyspark.sql.pandas._typing.protocols' to be distributed and are\n","          already explicitly excluding 'pyspark.sql.pandas._typing.protocols' via\n","          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","          you can try to use `exclude_package_data`, or `include-package-data=False` in\n","          combination with a more fine grained `package-data` configuration.\n","\n","          You can read more about \"package data files\" on setuptools documentation page:\n","\n","          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","          [^1]: For Python, any directory (with suitable naming) can be imported,\n","                even if it does not contain any `.py` files.\n","                On the other hand, currently there is no concept of package data\n","                directory, all directories are treated like packages.\n","          ********************************************************************************\n","\n","  !!\n","    check.warn(importable)\n","  copying pyspark/_typing.pyi -> build/lib/pyspark\n","  copying pyspark/py.typed -> build/lib/pyspark\n","  copying pyspark/mllib/_typing.pyi -> build/lib/pyspark/mllib\n","  copying pyspark/ml/_typing.pyi -> build/lib/pyspark/ml\n","  copying pyspark/sql/_typing.pyi -> build/lib/pyspark/sql\n","  copying pyspark/sql/connect/proto/base_pb2.pyi -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/catalog_pb2.pyi -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/commands_pb2.pyi -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/common_pb2.pyi -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/example_plugins_pb2.pyi -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/expressions_pb2.pyi -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/relations_pb2.pyi -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/connect/proto/types_pb2.pyi -> build/lib/pyspark/sql/connect/proto\n","  copying pyspark/sql/pandas/functions.pyi -> build/lib/pyspark/sql/pandas\n","  creating build/lib/pyspark/sql/pandas/_typing\n","  copying pyspark/sql/pandas/_typing/__init__.pyi -> build/lib/pyspark/sql/pandas/_typing\n","  creating build/lib/pyspark/sql/pandas/_typing/protocols\n","  copying pyspark/sql/pandas/_typing/protocols/__init__.pyi -> build/lib/pyspark/sql/pandas/_typing/protocols\n","  copying pyspark/sql/pandas/_typing/protocols/frame.pyi -> build/lib/pyspark/sql/pandas/_typing/protocols\n","  copying pyspark/sql/pandas/_typing/protocols/series.pyi -> build/lib/pyspark/sql/pandas/_typing/protocols\n","  creating build/lib/pyspark/bin\n","  copying deps/bin/beeline -> build/lib/pyspark/bin\n","  copying deps/bin/beeline.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/docker-image-tool.sh -> build/lib/pyspark/bin\n","  copying deps/bin/find-spark-home -> build/lib/pyspark/bin\n","  copying deps/bin/find-spark-home.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/load-spark-env.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/load-spark-env.sh -> build/lib/pyspark/bin\n","  copying deps/bin/pyspark -> build/lib/pyspark/bin\n","  copying deps/bin/pyspark.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/pyspark2.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/run-example -> build/lib/pyspark/bin\n","  copying deps/bin/run-example.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/spark-class -> build/lib/pyspark/bin\n","  copying deps/bin/spark-class.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/spark-class2.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/spark-connect-shell -> build/lib/pyspark/bin\n","  copying deps/bin/spark-shell -> build/lib/pyspark/bin\n","  copying deps/bin/spark-shell.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/spark-shell2.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/spark-sql -> build/lib/pyspark/bin\n","  copying deps/bin/spark-sql.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/spark-sql2.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/spark-submit -> build/lib/pyspark/bin\n","  copying deps/bin/spark-submit.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/spark-submit2.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/sparkR -> build/lib/pyspark/bin\n","  copying deps/bin/sparkR.cmd -> build/lib/pyspark/bin\n","  copying deps/bin/sparkR2.cmd -> build/lib/pyspark/bin\n","  creating build/lib/pyspark/sbin\n","  copying deps/sbin/spark-config.sh -> build/lib/pyspark/sbin\n","  copying deps/sbin/spark-daemon.sh -> build/lib/pyspark/sbin\n","  copying deps/sbin/start-history-server.sh -> build/lib/pyspark/sbin\n","  copying deps/sbin/stop-history-server.sh -> build/lib/pyspark/sbin\n","  creating build/lib/pyspark/jars\n","  copying deps/jars/HikariCP-2.5.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/JLargeArrays-1.5.jar -> build/lib/pyspark/jars\n","  copying deps/jars/JTransforms-3.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/RoaringBitmap-0.9.38.jar -> build/lib/pyspark/jars\n","  copying deps/jars/ST4-4.0.4.jar -> build/lib/pyspark/jars\n","  copying deps/jars/activation-1.1.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/aircompressor-0.21.jar -> build/lib/pyspark/jars\n","  copying deps/jars/algebra_2.12-2.0.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/annotations-17.0.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/antlr-runtime-3.5.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/antlr4-runtime-4.9.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/aopalliance-repackaged-2.6.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/arpack-3.0.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/arpack_combined_all-0.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/arrow-format-11.0.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/arrow-memory-core-11.0.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/arrow-memory-netty-11.0.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/arrow-vector-11.0.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/audience-annotations-0.5.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/avro-1.11.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/avro-ipc-1.11.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/avro-mapred-1.11.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/blas-3.0.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/bonecp-0.8.0.RELEASE.jar -> build/lib/pyspark/jars\n","  copying deps/jars/breeze-macros_2.12-2.1.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/breeze_2.12-2.1.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/cats-kernel_2.12-2.1.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/chill-java-0.10.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/chill_2.12-0.10.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-cli-1.5.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-codec-1.15.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-collections-3.2.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-collections4-4.4.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-compiler-3.1.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-compress-1.22.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-crypto-1.1.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-dbcp-1.4.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-io-2.11.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-lang-2.6.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-lang3-3.12.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-logging-1.1.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-math3-3.6.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-pool-1.5.4.jar -> build/lib/pyspark/jars\n","  copying deps/jars/commons-text-1.10.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/compress-lzf-1.1.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/curator-client-2.13.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/curator-framework-2.13.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/curator-recipes-2.13.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/datanucleus-api-jdo-4.2.4.jar -> build/lib/pyspark/jars\n","  copying deps/jars/datanucleus-core-4.1.17.jar -> build/lib/pyspark/jars\n","  copying deps/jars/datanucleus-rdbms-4.1.19.jar -> build/lib/pyspark/jars\n","  copying deps/jars/derby-10.14.2.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/flatbuffers-java-1.12.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/gson-2.2.4.jar -> build/lib/pyspark/jars\n","  copying deps/jars/guava-14.0.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hadoop-client-api-3.3.4.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hadoop-client-runtime-3.3.4.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hadoop-shaded-guava-1.1.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hadoop-yarn-server-web-proxy-3.3.4.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-beeline-2.3.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-cli-2.3.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-common-2.3.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-exec-2.3.9-core.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-jdbc-2.3.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-llap-common-2.3.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-metastore-2.3.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-serde-2.3.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-service-rpc-3.1.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-shims-0.23-2.3.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-shims-2.3.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-shims-common-2.3.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-shims-scheduler-2.3.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hive-storage-api-2.8.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hk2-api-2.6.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hk2-locator-2.6.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/hk2-utils-2.6.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/httpclient-4.5.14.jar -> build/lib/pyspark/jars\n","  copying deps/jars/httpcore-4.4.16.jar -> build/lib/pyspark/jars\n","  copying deps/jars/istack-commons-runtime-3.0.8.jar -> build/lib/pyspark/jars\n","  copying deps/jars/ivy-2.5.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jackson-annotations-2.14.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jackson-core-2.14.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jackson-core-asl-1.9.13.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jackson-databind-2.14.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jackson-dataformat-yaml-2.14.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jackson-datatype-jsr310-2.14.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jackson-mapper-asl-1.9.13.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jackson-module-scala_2.12-2.14.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jakarta.annotation-api-1.3.5.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jakarta.inject-2.6.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jakarta.servlet-api-4.0.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jakarta.validation-api-2.0.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jakarta.ws.rs-api-2.1.6.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jakarta.xml.bind-api-2.3.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/janino-3.1.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/javassist-3.25.0-GA.jar -> build/lib/pyspark/jars\n","  copying deps/jars/javax.jdo-3.2.0-m3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/javolution-5.5.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jaxb-runtime-2.3.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jcl-over-slf4j-2.0.6.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jdo-api-3.0.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jersey-client-2.36.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jersey-common-2.36.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jersey-container-servlet-2.36.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jersey-container-servlet-core-2.36.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jersey-hk2-2.36.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jersey-server-2.36.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jline-2.14.6.jar -> build/lib/pyspark/jars\n","  copying deps/jars/joda-time-2.12.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jodd-core-3.5.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jpam-1.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/json-1.8.jar -> build/lib/pyspark/jars\n","  copying deps/jars/json4s-ast_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n","  copying deps/jars/json4s-core_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n","  copying deps/jars/json4s-jackson_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n","  copying deps/jars/json4s-scalap_2.12-3.7.0-M11.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jsr305-3.0.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jta-1.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/jul-to-slf4j-2.0.6.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kryo-shaded-4.0.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-client-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-client-api-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-httpclient-okhttp-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-admissionregistration-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-apiextensions-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-apps-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-autoscaling-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-batch-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-certificates-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-common-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-coordination-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-core-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-discovery-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-events-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-extensions-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-flowcontrol-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-gatewayapi-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-metrics-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-networking-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-node-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-policy-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-rbac-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-scheduling-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/kubernetes-model-storageclass-6.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/lapack-3.0.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/leveldbjni-all-1.8.jar -> build/lib/pyspark/jars\n","  copying deps/jars/libfb303-0.9.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/libthrift-0.12.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/log4j-1.2-api-2.19.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/log4j-api-2.19.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/log4j-core-2.19.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/log4j-slf4j2-impl-2.19.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/logging-interceptor-3.12.12.jar -> build/lib/pyspark/jars\n","  copying deps/jars/lz4-java-1.8.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/mesos-1.4.3-shaded-protobuf.jar -> build/lib/pyspark/jars\n","  copying deps/jars/metrics-core-4.2.15.jar -> build/lib/pyspark/jars\n","  copying deps/jars/metrics-graphite-4.2.15.jar -> build/lib/pyspark/jars\n","  copying deps/jars/metrics-jmx-4.2.15.jar -> build/lib/pyspark/jars\n","  copying deps/jars/metrics-json-4.2.15.jar -> build/lib/pyspark/jars\n","  copying deps/jars/metrics-jvm-4.2.15.jar -> build/lib/pyspark/jars\n","  copying deps/jars/minlog-1.3.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-all-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-buffer-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-codec-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-codec-http-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-codec-http2-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-codec-socks-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-common-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-handler-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-handler-proxy-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-resolver-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-transport-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-transport-classes-epoll-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-transport-classes-kqueue-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-transport-native-epoll-4.1.87.Final-linux-aarch_64.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-transport-native-epoll-4.1.87.Final-linux-x86_64.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-transport-native-kqueue-4.1.87.Final-osx-aarch_64.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-transport-native-kqueue-4.1.87.Final-osx-x86_64.jar -> build/lib/pyspark/jars\n","  copying deps/jars/netty-transport-native-unix-common-4.1.87.Final.jar -> build/lib/pyspark/jars\n","  copying deps/jars/objenesis-3.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/okhttp-3.12.12.jar -> build/lib/pyspark/jars\n","  copying deps/jars/okio-1.15.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/opencsv-2.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/orc-core-1.8.4-shaded-protobuf.jar -> build/lib/pyspark/jars\n","  copying deps/jars/orc-mapreduce-1.8.4-shaded-protobuf.jar -> build/lib/pyspark/jars\n","  copying deps/jars/orc-shims-1.8.4.jar -> build/lib/pyspark/jars\n","  copying deps/jars/oro-2.0.8.jar -> build/lib/pyspark/jars\n","  copying deps/jars/osgi-resource-locator-1.0.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/paranamer-2.8.jar -> build/lib/pyspark/jars\n","  copying deps/jars/parquet-column-1.12.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/parquet-common-1.12.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/parquet-encoding-1.12.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/parquet-format-structures-1.12.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/parquet-hadoop-1.12.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/parquet-jackson-1.12.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/pickle-1.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/protobuf-java-2.5.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/py4j-0.10.9.7.jar -> build/lib/pyspark/jars\n","  copying deps/jars/rocksdbjni-7.9.2.jar -> build/lib/pyspark/jars\n","  copying deps/jars/scala-collection-compat_2.12-2.7.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/scala-compiler-2.12.17.jar -> build/lib/pyspark/jars\n","  copying deps/jars/scala-library-2.12.17.jar -> build/lib/pyspark/jars\n","  copying deps/jars/scala-parser-combinators_2.12-2.1.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/scala-reflect-2.12.17.jar -> build/lib/pyspark/jars\n","  copying deps/jars/scala-xml_2.12-2.1.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/shims-0.9.38.jar -> build/lib/pyspark/jars\n","  copying deps/jars/slf4j-api-2.0.6.jar -> build/lib/pyspark/jars\n","  copying deps/jars/snakeyaml-1.33.jar -> build/lib/pyspark/jars\n","  copying deps/jars/snappy-java-1.1.10.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-catalyst_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-core_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-graphx_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-hive-thriftserver_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-hive_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-kubernetes_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-kvstore_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-launcher_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-mesos_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-mllib-local_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-mllib_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-network-common_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-network-shuffle_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-repl_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-sketch_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-sql_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-streaming_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-tags_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-unsafe_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spark-yarn_2.12-3.4.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spire-macros_2.12-0.17.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spire-platform_2.12-0.17.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spire-util_2.12-0.17.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/spire_2.12-0.17.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/stax-api-1.0.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/stream-2.9.6.jar -> build/lib/pyspark/jars\n","  copying deps/jars/super-csv-2.2.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/threeten-extra-1.7.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/tink-1.7.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/transaction-api-1.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/univocity-parsers-2.9.1.jar -> build/lib/pyspark/jars\n","  copying deps/jars/xbean-asm9-shaded-4.22.jar -> build/lib/pyspark/jars\n","  copying deps/jars/xz-1.9.jar -> build/lib/pyspark/jars\n","  copying deps/jars/zjsonpatch-0.3.0.jar -> build/lib/pyspark/jars\n","  copying deps/jars/zookeeper-3.6.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/zookeeper-jute-3.6.3.jar -> build/lib/pyspark/jars\n","  copying deps/jars/zstd-jni-1.5.2-5.jar -> build/lib/pyspark/jars\n","  creating build/lib/pyspark/python/lib\n","  copying lib/py4j-0.10.9.7-src.zip -> build/lib/pyspark/python/lib\n","  copying lib/pyspark.zip -> build/lib/pyspark/python/lib\n","  creating build/lib/pyspark/data\n","  creating build/lib/pyspark/data/graphx\n","  copying deps/data/graphx/followers.txt -> build/lib/pyspark/data/graphx\n","  copying deps/data/graphx/users.txt -> build/lib/pyspark/data/graphx\n","  creating build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/gmm_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/kmeans_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/pagerank_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/pic_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/sample_binary_classification_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/sample_fpgrowth.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/sample_isotonic_regression_libsvm_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/sample_kmeans_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/sample_lda_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/sample_lda_libsvm_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/sample_libsvm_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/sample_linear_regression_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/sample_movielens_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/sample_multiclass_classification_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/sample_svm_data.txt -> build/lib/pyspark/data/mllib\n","  copying deps/data/mllib/streaming_kmeans_data_test.txt -> build/lib/pyspark/data/mllib\n","  creating build/lib/pyspark/data/mllib/als\n","  copying deps/data/mllib/als/sample_movielens_ratings.txt -> build/lib/pyspark/data/mllib/als\n","  copying deps/data/mllib/als/test.data -> build/lib/pyspark/data/mllib/als\n","  creating build/lib/pyspark/data/mllib/images\n","  copying deps/data/mllib/images/license.txt -> build/lib/pyspark/data/mllib/images\n","  creating build/lib/pyspark/data/mllib/images/origin\n","  copying deps/data/mllib/images/origin/license.txt -> build/lib/pyspark/data/mllib/images/origin\n","  creating build/lib/pyspark/data/mllib/images/origin/kittens\n","  copying deps/data/mllib/images/origin/kittens/not-image.txt -> build/lib/pyspark/data/mllib/images/origin/kittens\n","  creating build/lib/pyspark/data/mllib/ridge-data\n","  copying deps/data/mllib/ridge-data/lpsa.data -> build/lib/pyspark/data/mllib/ridge-data\n","  creating build/lib/pyspark/data/streaming\n","  copying deps/data/streaming/AFINN-111.txt -> build/lib/pyspark/data/streaming\n","  creating build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-AnchorJS.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-CC0.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-bootstrap.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-cloudpickle.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-copybutton.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-d3.min.js.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-dagre-d3.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-datatables.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-graphlib-dot.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-jdom.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-join.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-jquery.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-json-formatter.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-matchMedia-polyfill.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-modernizr.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-mustache.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-py4j.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-respond.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-sbt-launch-lib.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-sorttable.js.txt -> build/lib/pyspark/licenses\n","  copying deps/licenses/LICENSE-vis-timeline.txt -> build/lib/pyspark/licenses\n","  creating build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/aft_survival_regression.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/als_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/binarizer_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/bisecting_k_means_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/bucketed_random_projection_lsh_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/bucketizer_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/chi_square_test_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/chisq_selector_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/correlation_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/count_vectorizer_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/cross_validator.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/dataframe_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/dct_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/decision_tree_classification_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/decision_tree_regression_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/elementwise_product_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/estimator_transformer_param_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/feature_hasher_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/fm_classifier_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/fm_regressor_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/fpgrowth_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/gaussian_mixture_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/generalized_linear_regression_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/gradient_boosted_tree_classifier_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/gradient_boosted_tree_regressor_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/imputer_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/index_to_string_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/interaction_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/isotonic_regression_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/kmeans_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/lda_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/linear_regression_with_elastic_net.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/linearsvc.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/logistic_regression_summary_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/logistic_regression_with_elastic_net.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/max_abs_scaler_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/min_hash_lsh_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/min_max_scaler_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/multiclass_logistic_regression_with_elastic_net.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/multilayer_perceptron_classification.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/n_gram_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/naive_bayes_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/normalizer_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/one_vs_rest_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/onehot_encoder_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/pca_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/pipeline_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/polynomial_expansion_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/power_iteration_clustering_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/prefixspan_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/quantile_discretizer_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/random_forest_classifier_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/random_forest_regressor_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/rformula_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/robust_scaler_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/sql_transformer.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/standard_scaler_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/stopwords_remover_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/string_indexer_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/summarizer_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/tf_idf_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/tokenizer_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/train_validation_split.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/univariate_feature_selector_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/variance_threshold_selector_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/vector_assembler_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/vector_indexer_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/vector_size_hint_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/vector_slicer_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  copying deps/examples/ml/word2vec_example.py -> build/lib/pyspark/examples/src/main/python/ml\n","  creating build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/__init__.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/binary_classification_metrics_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/bisecting_k_means_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/correlations.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/correlations_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/decision_tree_classification_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/decision_tree_regression_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/elementwise_product_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/fpgrowth_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/gaussian_mixture_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/gaussian_mixture_model.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/gradient_boosting_classification_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/gradient_boosting_regression_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/hypothesis_testing_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/isotonic_regression_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/k_means_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/kernel_density_estimation_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/kmeans.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/latent_dirichlet_allocation_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/linear_regression_with_sgd_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/logistic_regression.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/logistic_regression_with_lbfgs_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/multi_class_metrics_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/multi_label_metrics_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/naive_bayes_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/normalizer_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/pca_rowmatrix_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/power_iteration_clustering_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/random_forest_classification_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/random_forest_regression_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/random_rdd_generation.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/ranking_metrics_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/recommendation_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/regression_metrics_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/sampled_rdds.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/standard_scaler_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/stratified_sampling_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/streaming_k_means_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/streaming_linear_regression_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/summary_statistics_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/svd_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/svm_with_sgd_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/tf_idf_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/word2vec.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  copying deps/examples/mllib/word2vec_example.py -> build/lib/pyspark/examples/src/main/python/mllib\n","  creating build/lib/pyspark/examples/src/main/python/sql\n","  copying deps/examples/sql/__init__.py -> build/lib/pyspark/examples/src/main/python/sql\n","  copying deps/examples/sql/arrow.py -> build/lib/pyspark/examples/src/main/python/sql\n","  copying deps/examples/sql/basic.py -> build/lib/pyspark/examples/src/main/python/sql\n","  copying deps/examples/sql/datasource.py -> build/lib/pyspark/examples/src/main/python/sql\n","  copying deps/examples/sql/hive.py -> build/lib/pyspark/examples/src/main/python/sql\n","  creating build/lib/pyspark/examples/src/main/python/sql/streaming\n","  copying deps/examples/sql/streaming/structured_kafka_wordcount.py -> build/lib/pyspark/examples/src/main/python/sql/streaming\n","  copying deps/examples/sql/streaming/structured_network_wordcount.py -> build/lib/pyspark/examples/src/main/python/sql/streaming\n","  copying deps/examples/sql/streaming/structured_network_wordcount_session_window.py -> build/lib/pyspark/examples/src/main/python/sql/streaming\n","  copying deps/examples/sql/streaming/structured_network_wordcount_windowed.py -> build/lib/pyspark/examples/src/main/python/sql/streaming\n","  copying deps/examples/sql/streaming/structured_sessionization.py -> build/lib/pyspark/examples/src/main/python/sql/streaming\n","  creating build/lib/pyspark/examples/src/main/python/streaming\n","  copying deps/examples/streaming/__init__.py -> build/lib/pyspark/examples/src/main/python/streaming\n","  copying deps/examples/streaming/hdfs_wordcount.py -> build/lib/pyspark/examples/src/main/python/streaming\n","  copying deps/examples/streaming/network_wordcount.py -> build/lib/pyspark/examples/src/main/python/streaming\n","  copying deps/examples/streaming/network_wordjoinsentiments.py -> build/lib/pyspark/examples/src/main/python/streaming\n","  copying deps/examples/streaming/queue_stream.py -> build/lib/pyspark/examples/src/main/python/streaming\n","  copying deps/examples/streaming/recoverable_network_wordcount.py -> build/lib/pyspark/examples/src/main/python/streaming\n","  copying deps/examples/streaming/sql_network_wordcount.py -> build/lib/pyspark/examples/src/main/python/streaming\n","  copying deps/examples/streaming/stateful_network_wordcount.py -> build/lib/pyspark/examples/src/main/python/streaming\n","  running build_scripts\n","  creating build/scripts-3.10\n","  copying deps/bin/pyspark.cmd -> build/scripts-3.10\n","  copying deps/bin/beeline -> build/scripts-3.10\n","  copying deps/bin/load-spark-env.cmd -> build/scripts-3.10\n","  copying deps/bin/spark-class2.cmd -> build/scripts-3.10\n","  copying deps/bin/find-spark-home -> build/scripts-3.10\n","  copying deps/bin/spark-shell -> build/scripts-3.10\n","  copying deps/bin/find-spark-home.cmd -> build/scripts-3.10\n","  copying deps/bin/sparkR2.cmd -> build/scripts-3.10\n","  copying deps/bin/spark-sql2.cmd -> build/scripts-3.10\n","  copying deps/bin/sparkR -> build/scripts-3.10\n","  copying deps/bin/docker-image-tool.sh -> build/scripts-3.10\n","  copying deps/bin/sparkR.cmd -> build/scripts-3.10\n","  copying deps/bin/run-example.cmd -> build/scripts-3.10\n","  copying deps/bin/spark-class.cmd -> build/scripts-3.10\n","  copying deps/bin/spark-shell.cmd -> build/scripts-3.10\n","  copying deps/bin/spark-sql -> build/scripts-3.10\n","  copying deps/bin/spark-sql.cmd -> build/scripts-3.10\n","  copying deps/bin/spark-submit2.cmd -> build/scripts-3.10\n","  copying deps/bin/pyspark2.cmd -> build/scripts-3.10\n","  copying deps/bin/spark-submit.cmd -> build/scripts-3.10\n","  copying deps/bin/spark-submit -> build/scripts-3.10\n","  copying deps/bin/beeline.cmd -> build/scripts-3.10\n","  copying deps/bin/spark-connect-shell -> build/scripts-3.10\n","  copying deps/bin/load-spark-env.sh -> build/scripts-3.10\n","  copying deps/bin/spark-class -> build/scripts-3.10\n","  copying deps/bin/pyspark -> build/scripts-3.10\n","  copying deps/bin/spark-shell2.cmd -> build/scripts-3.10\n","  copying deps/bin/run-example -> build/scripts-3.10\n","  copying and adjusting pyspark/find_spark_home.py -> build/scripts-3.10\n","  changing mode of build/scripts-3.10/pyspark.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/load-spark-env.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/find-spark-home.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/sparkR2.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/spark-sql2.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/sparkR.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/run-example.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/spark-class.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/spark-shell.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/spark-sql.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/spark-submit2.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/pyspark2.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/spark-submit.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/beeline.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/load-spark-env.sh from 644 to 755\n","  changing mode of build/scripts-3.10/spark-shell2.cmd from 644 to 755\n","  changing mode of build/scripts-3.10/find_spark_home.py from 644 to 755\n","  /usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n","  !!\n","\n","          ********************************************************************************\n","          Please avoid running ``setup.py`` directly.\n","          Instead, use pypa/build, pypa/installer, pypa/build or\n","          other standards-based tools.\n","\n","          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n","          ********************************************************************************\n","\n","  !!\n","    self.initialize_options()\n","  installing to build/bdist.linux-x86_64/wheel\n","  running install\n","  running install_lib\n","  creating build/bdist.linux-x86_64\n","  creating build/bdist.linux-x86_64/wheel\n","  creating build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/storagelevel.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/instrumentation_utils.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/traceback_utils.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-py4j.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-datatables.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-mustache.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-sorttable.js.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-CC0.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-join.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-jquery.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-vis-timeline.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-matchMedia-polyfill.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-sbt-launch-lib.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-modernizr.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-copybutton.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-dagre-d3.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-jdom.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-respond.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-bootstrap.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-cloudpickle.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-AnchorJS.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-d3.min.js.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-json-formatter.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  copying build/lib/pyspark/licenses/LICENSE-graphlib-dot.txt -> build/bdist.linux-x86_64/wheel/pyspark/licenses\n","  creating build/bdist.linux-x86_64/wheel/pyspark/examples\n","  creating build/bdist.linux-x86_64/wheel/pyspark/examples/src\n","  creating build/bdist.linux-x86_64/wheel/pyspark/examples/src/main\n","  creating build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  copying build/lib/pyspark/examples/src/main/python/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  copying build/lib/pyspark/examples/src/main/python/logistic_regression.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  creating build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/random_forest_classifier_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/rformula_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/train_validation_split.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/logistic_regression_with_elastic_net.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/pca_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/max_abs_scaler_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/pipeline_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/kmeans_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/feature_hasher_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/isotonic_regression_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/tokenizer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/normalizer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/sql_transformer.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/fpgrowth_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/multilayer_perceptron_classification.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/logistic_regression_summary_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/generalized_linear_regression_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/bucketizer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/vector_slicer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/string_indexer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/linearsvc.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/aft_survival_regression.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/decision_tree_classification_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/cross_validator.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/min_max_scaler_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/chisq_selector_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/chi_square_test_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/variance_threshold_selector_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/tf_idf_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/elementwise_product_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/estimator_transformer_param_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/lda_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/linear_regression_with_elastic_net.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/robust_scaler_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/count_vectorizer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/correlation_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/fm_classifier_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/min_hash_lsh_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/vector_indexer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/dct_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/imputer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/quantile_discretizer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/als_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/power_iteration_clustering_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/index_to_string_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/polynomial_expansion_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/fm_regressor_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/n_gram_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/univariate_feature_selector_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/standard_scaler_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/one_vs_rest_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/word2vec_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/vector_size_hint_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/interaction_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/dataframe_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/onehot_encoder_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/random_forest_regressor_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/summarizer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/decision_tree_regression_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/stopwords_remover_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/vector_assembler_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/prefixspan_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/binarizer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/naive_bayes_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/bisecting_k_means_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/ml/gaussian_mixture_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/ml\n","  copying build/lib/pyspark/examples/src/main/python/sort.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  creating build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/streaming\n","  copying build/lib/pyspark/examples/src/main/python/streaming/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/streaming\n","  copying build/lib/pyspark/examples/src/main/python/streaming/network_wordjoinsentiments.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/streaming\n","  copying build/lib/pyspark/examples/src/main/python/streaming/hdfs_wordcount.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/streaming\n","  copying build/lib/pyspark/examples/src/main/python/streaming/network_wordcount.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/streaming\n","  copying build/lib/pyspark/examples/src/main/python/streaming/sql_network_wordcount.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/streaming\n","  copying build/lib/pyspark/examples/src/main/python/streaming/recoverable_network_wordcount.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/streaming\n","  copying build/lib/pyspark/examples/src/main/python/streaming/stateful_network_wordcount.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/streaming\n","  copying build/lib/pyspark/examples/src/main/python/streaming/queue_stream.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/streaming\n","  copying build/lib/pyspark/examples/src/main/python/parquet_inputformat.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  creating build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/binary_classification_metrics_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/gradient_boosting_classification_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/summary_statistics_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/hypothesis_testing_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/ranking_metrics_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/stratified_sampling_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/correlations_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/isotonic_regression_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/normalizer_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/regression_metrics_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/fpgrowth_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/svm_with_sgd_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/logistic_regression.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/recommendation_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/decision_tree_classification_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/streaming_k_means_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/gaussian_mixture_model.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/tf_idf_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/elementwise_product_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/correlations.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/sampled_rdds.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/streaming_linear_regression_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/kernel_density_estimation_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/pca_rowmatrix_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/random_forest_regression_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/multi_label_metrics_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/linear_regression_with_sgd_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/multi_class_metrics_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/power_iteration_clustering_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/word2vec.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/standard_scaler_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/random_forest_classification_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/random_rdd_generation.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/word2vec_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/gradient_boosting_regression_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/kmeans.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/svd_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/decision_tree_regression_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/naive_bayes_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/bisecting_k_means_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/gaussian_mixture_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/mllib/k_means_example.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/mllib\n","  copying build/lib/pyspark/examples/src/main/python/avro_inputformat.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  copying build/lib/pyspark/examples/src/main/python/transitive_closure.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  copying build/lib/pyspark/examples/src/main/python/status_api_demo.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  copying build/lib/pyspark/examples/src/main/python/pi.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  copying build/lib/pyspark/examples/src/main/python/wordcount.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  copying build/lib/pyspark/examples/src/main/python/pagerank.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  copying build/lib/pyspark/examples/src/main/python/kmeans.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  creating build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql\n","  copying build/lib/pyspark/examples/src/main/python/sql/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql\n","  copying build/lib/pyspark/examples/src/main/python/sql/hive.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql\n","  copying build/lib/pyspark/examples/src/main/python/sql/datasource.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql\n","  creating build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql/streaming\n","  copying build/lib/pyspark/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql/streaming\n","  copying build/lib/pyspark/examples/src/main/python/sql/streaming/structured_network_wordcount.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql/streaming\n","  copying build/lib/pyspark/examples/src/main/python/sql/streaming/structured_sessionization.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql/streaming\n","  copying build/lib/pyspark/examples/src/main/python/sql/streaming/structured_network_wordcount_session_window.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql/streaming\n","  copying build/lib/pyspark/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql/streaming\n","  copying build/lib/pyspark/examples/src/main/python/sql/arrow.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql\n","  copying build/lib/pyspark/examples/src/main/python/sql/basic.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python/sql\n","  copying build/lib/pyspark/examples/src/main/python/als.py -> build/bdist.linux-x86_64/wheel/pyspark/examples/src/main/python\n","  creating build/bdist.linux-x86_64/wheel/pyspark/python\n","  creating build/bdist.linux-x86_64/wheel/pyspark/python/lib\n","  copying build/lib/pyspark/python/lib/pyspark.zip -> build/bdist.linux-x86_64/wheel/pyspark/python/lib\n","  copying build/lib/pyspark/python/lib/py4j-0.10.9.7-src.zip -> build/bdist.linux-x86_64/wheel/pyspark/python/lib\n","  creating build/bdist.linux-x86_64/wheel/pyspark/python/pyspark\n","  copying build/lib/pyspark/python/pyspark/shell.py -> build/bdist.linux-x86_64/wheel/pyspark/python/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/sbin\n","  copying build/lib/pyspark/sbin/spark-config.sh -> build/bdist.linux-x86_64/wheel/pyspark/sbin\n","  copying build/lib/pyspark/sbin/spark-daemon.sh -> build/bdist.linux-x86_64/wheel/pyspark/sbin\n","  copying build/lib/pyspark/sbin/start-history-server.sh -> build/bdist.linux-x86_64/wheel/pyspark/sbin\n","  copying build/lib/pyspark/sbin/stop-history-server.sh -> build/bdist.linux-x86_64/wheel/pyspark/sbin\n","  creating build/bdist.linux-x86_64/wheel/pyspark/data\n","  creating build/bdist.linux-x86_64/wheel/pyspark/data/streaming\n","  copying build/lib/pyspark/data/streaming/AFINN-111.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/streaming\n","  creating build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/sample_binary_classification_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/sample_kmeans_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/sample_lda_libsvm_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/pic_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/sample_fpgrowth.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/kmeans_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/gmm_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/sample_multiclass_classification_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/sample_linear_regression_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  creating build/bdist.linux-x86_64/wheel/pyspark/data/mllib/images\n","  copying build/lib/pyspark/data/mllib/images/license.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib/images\n","  creating build/bdist.linux-x86_64/wheel/pyspark/data/mllib/images/origin\n","  copying build/lib/pyspark/data/mllib/images/origin/license.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib/images/origin\n","  creating build/bdist.linux-x86_64/wheel/pyspark/data/mllib/images/origin/kittens\n","  copying build/lib/pyspark/data/mllib/images/origin/kittens/not-image.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib/images/origin/kittens\n","  copying build/lib/pyspark/data/mllib/pagerank_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/sample_movielens_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/streaming_kmeans_data_test.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  creating build/bdist.linux-x86_64/wheel/pyspark/data/mllib/als\n","  copying build/lib/pyspark/data/mllib/als/test.data -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib/als\n","  copying build/lib/pyspark/data/mllib/als/sample_movielens_ratings.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib/als\n","  copying build/lib/pyspark/data/mllib/sample_libsvm_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/sample_lda_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  copying build/lib/pyspark/data/mllib/sample_svm_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  creating build/bdist.linux-x86_64/wheel/pyspark/data/mllib/ridge-data\n","  copying build/lib/pyspark/data/mllib/ridge-data/lpsa.data -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib/ridge-data\n","  copying build/lib/pyspark/data/mllib/sample_isotonic_regression_libsvm_data.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/mllib\n","  creating build/bdist.linux-x86_64/wheel/pyspark/data/graphx\n","  copying build/lib/pyspark/data/graphx/followers.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/graphx\n","  copying build/lib/pyspark/data/graphx/users.txt -> build/bdist.linux-x86_64/wheel/pyspark/data/graphx\n","  copying build/lib/pyspark/_globals.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/model_cache.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/pipeline.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/common.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  creating build/bdist.linux-x86_64/wheel/pyspark/ml/torch\n","  copying build/lib/pyspark/ml/torch/torch_run_process_wrapper.py -> build/bdist.linux-x86_64/wheel/pyspark/ml/torch\n","  copying build/lib/pyspark/ml/torch/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/ml/torch\n","  copying build/lib/pyspark/ml/torch/distributor.py -> build/bdist.linux-x86_64/wheel/pyspark/ml/torch\n","  copying build/lib/pyspark/ml/torch/log_communication.py -> build/bdist.linux-x86_64/wheel/pyspark/ml/torch\n","  copying build/lib/pyspark/ml/wrapper.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  creating build/bdist.linux-x86_64/wheel/pyspark/ml/linalg\n","  copying build/lib/pyspark/ml/linalg/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/ml/linalg\n","  copying build/lib/pyspark/ml/_typing.pyi -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/feature.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/tree.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/classification.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/stat.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  creating build/bdist.linux-x86_64/wheel/pyspark/ml/param\n","  copying build/lib/pyspark/ml/param/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/ml/param\n","  copying build/lib/pyspark/ml/param/shared.py -> build/bdist.linux-x86_64/wheel/pyspark/ml/param\n","  copying build/lib/pyspark/ml/param/_shared_params_code_gen.py -> build/bdist.linux-x86_64/wheel/pyspark/ml/param\n","  copying build/lib/pyspark/ml/regression.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/clustering.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/recommendation.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/evaluation.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/image.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/base.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/fpm.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/functions.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/tuning.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/ml/util.py -> build/bdist.linux-x86_64/wheel/pyspark/ml\n","  copying build/lib/pyspark/py.typed -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/rdd.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/version.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/cloudpickle\n","  copying build/lib/pyspark/cloudpickle/cloudpickle.py -> build/bdist.linux-x86_64/wheel/pyspark/cloudpickle\n","  copying build/lib/pyspark/cloudpickle/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/cloudpickle\n","  copying build/lib/pyspark/cloudpickle/cloudpickle_fast.py -> build/bdist.linux-x86_64/wheel/pyspark/cloudpickle\n","  copying build/lib/pyspark/cloudpickle/compat.py -> build/bdist.linux-x86_64/wheel/pyspark/cloudpickle\n","  copying build/lib/pyspark/statcounter.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/find_spark_home.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/conf.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/shell.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/files.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-common-2.3.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-certificates-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-compiler-3.1.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/json4s-ast_2.12-3.7.0-M11.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-core-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-shims-0.23-2.3.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jakarta.ws.rs-api-2.1.6.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-kvstore_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/ST4-4.0.4.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/avro-1.11.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jul-to-slf4j-2.0.6.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-jdbc-2.3.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/httpclient-4.5.14.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-exec-2.3.9-core.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/curator-recipes-2.13.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/JLargeArrays-1.5.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jackson-module-scala_2.12-2.14.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jakarta.inject-2.6.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/okio-1.15.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-shims-scheduler-2.3.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jakarta.validation-api-2.0.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kryo-shaded-4.0.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/gson-2.2.4.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-mllib-local_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/parquet-hadoop-1.12.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/parquet-format-structures-1.12.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/curator-framework-2.13.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/leveldbjni-all-1.8.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jackson-mapper-asl-1.9.13.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/scala-parser-combinators_2.12-2.1.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/paranamer-2.8.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/RoaringBitmap-0.9.38.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jdo-api-3.0.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/orc-mapreduce-1.8.4-shaded-protobuf.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/lapack-3.0.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/audience-annotations-0.5.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/cats-kernel_2.12-2.1.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-buffer-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-networking-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spire_2.12-0.17.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-core_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jsr305-3.0.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-extensions-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jcl-over-slf4j-2.0.6.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-pool-1.5.4.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-cli-1.5.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-transport-native-kqueue-4.1.87.Final-osx-x86_64.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-common-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jersey-container-servlet-core-2.36.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/datanucleus-api-jdo-4.2.4.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/HikariCP-2.5.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/blas-3.0.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/mesos-1.4.3-shaded-protobuf.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/zookeeper-jute-3.6.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jline-2.14.6.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/json4s-jackson_2.12-3.7.0-M11.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/antlr-runtime-3.5.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/arrow-memory-core-11.0.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jackson-annotations-2.14.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-cli-2.3.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/json-1.8.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-dbcp-1.4.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/pickle-1.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/chill_2.12-0.10.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jackson-dataformat-yaml-2.14.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-network-common_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/javolution-5.5.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-policy-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/annotations-17.0.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/snakeyaml-1.33.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/istack-commons-runtime-3.0.8.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/zstd-jni-1.5.2-5.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/parquet-encoding-1.12.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/metrics-json-4.2.15.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/metrics-jmx-4.2.15.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/algebra_2.12-2.0.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/super-csv-2.2.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-transport-native-kqueue-4.1.87.Final-osx-aarch_64.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/parquet-common-1.12.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-apiextensions-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/scala-reflect-2.12.17.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/flatbuffers-java-1.12.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hadoop-client-api-3.3.4.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/aircompressor-0.21.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/guava-14.0.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-codec-1.15.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/ivy-2.5.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-unsafe_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-sql_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/lz4-java-1.8.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hk2-locator-2.6.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-network-shuffle_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/xz-1.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/activation-1.1.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jersey-container-servlet-2.36.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-apps-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/httpcore-4.4.16.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/joda-time-2.12.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/arrow-memory-netty-11.0.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/py4j-0.10.9.7.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-codec-http-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jakarta.xml.bind-api-2.3.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/zjsonpatch-0.3.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-events-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/arrow-vector-11.0.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/rocksdbjni-7.9.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/arrow-format-11.0.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-lang-2.6.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/metrics-graphite-4.2.15.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/logging-interceptor-3.12.12.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spire-macros_2.12-0.17.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/libthrift-0.12.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/compress-lzf-1.1.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/javassist-3.25.0-GA.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hadoop-client-runtime-3.3.4.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-compress-1.22.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/tink-1.7.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-client-api-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-mllib_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-resolver-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-math3-3.6.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/curator-client-2.13.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-client-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-autoscaling-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/slf4j-api-2.0.6.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jackson-datatype-jsr310-2.14.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/metrics-core-4.2.15.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-logging-1.1.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/objenesis-3.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-service-rpc-3.1.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-discovery-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/derby-10.14.2.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-streaming_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-transport-classes-epoll-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/log4j-core-2.19.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/zookeeper-3.6.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/bonecp-0.8.0.RELEASE.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jpam-1.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-common-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-kubernetes_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jodd-core-3.5.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hadoop-yarn-server-web-proxy-3.3.4.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-node-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/avro-ipc-1.11.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jackson-databind-2.14.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-shims-common-2.3.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jersey-client-2.36.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-mesos_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/parquet-column-1.12.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/univocity-parsers-2.9.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-repl_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-graphx_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/metrics-jvm-4.2.15.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-codec-http2-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/protobuf-java-2.5.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/oro-2.0.8.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-rbac-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/datanucleus-rdbms-4.1.19.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/json4s-core_2.12-3.7.0-M11.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-scheduling-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-tags_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-catalyst_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-metastore-2.3.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-text-1.10.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-gatewayapi-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-codec-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/scala-xml_2.12-2.1.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/scala-compiler-2.12.17.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/JTransforms-3.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jersey-common-2.36.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/parquet-jackson-1.12.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/osgi-resource-locator-1.0.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/opencsv-2.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/json4s-scalap_2.12-3.7.0-M11.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-lang3-3.12.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/breeze-macros_2.12-2.1.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-transport-classes-kqueue-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/stax-api-1.0.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-hive-thriftserver_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-sketch_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/orc-core-1.8.4-shaded-protobuf.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-io-2.11.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-shims-2.3.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-codec-socks-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/antlr4-runtime-4.9.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-hive_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jackson-core-asl-1.9.13.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-launcher_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/breeze_2.12-2.1.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spire-util_2.12-0.17.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/transaction-api-1.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-transport-native-epoll-4.1.87.Final-linux-aarch_64.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/chill-java-0.10.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-llap-common-2.3.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jackson-core-2.14.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/libfb303-0.9.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/janino-3.1.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-batch-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-handler-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-collections4-4.4.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/scala-library-2.12.17.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-crypto-1.1.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spark-yarn_2.12-3.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-transport-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-handler-proxy-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/threeten-extra-1.7.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-admissionregistration-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/arpack-3.0.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/snappy-java-1.1.10.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/spire-platform_2.12-0.17.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-beeline-2.3.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/okhttp-3.12.12.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hk2-utils-2.6.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jersey-hk2-2.36.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hk2-api-2.6.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/minlog-1.3.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/xbean-asm9-shaded-4.22.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-serde-2.3.9.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/javax.jdo-3.2.0-m3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-coordination-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/scala-collection-compat_2.12-2.7.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-httpclient-okhttp-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-all-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/arpack_combined_all-0.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jakarta.annotation-api-1.3.5.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hive-storage-api-2.8.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/avro-mapred-1.11.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jaxb-runtime-2.3.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/log4j-slf4j2-impl-2.19.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/stream-2.9.6.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jersey-server-2.36.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/hadoop-shaded-guava-1.1.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/log4j-1.2-api-2.19.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/orc-shims-1.8.4.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jta-1.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-metrics-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/jakarta.servlet-api-4.0.3.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/shims-0.9.38.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-transport-native-unix-common-4.1.87.Final.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/aopalliance-repackaged-2.6.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/netty-transport-native-epoll-4.1.87.Final-linux-x86_64.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/log4j-api-2.19.0.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/commons-collections-3.2.2.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/datanucleus-core-4.1.17.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-flowcontrol-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/jars/kubernetes-model-storageclass-6.4.1.jar -> build/bdist.linux-x86_64/wheel/pyspark/jars\n","  copying build/lib/pyspark/_typing.pyi -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/status.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/rddsampler.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/streaming\n","  copying build/lib/pyspark/streaming/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/streaming\n","  copying build/lib/pyspark/streaming/kinesis.py -> build/bdist.linux-x86_64/wheel/pyspark/streaming\n","  copying build/lib/pyspark/streaming/listener.py -> build/bdist.linux-x86_64/wheel/pyspark/streaming\n","  copying build/lib/pyspark/streaming/dstream.py -> build/bdist.linux-x86_64/wheel/pyspark/streaming\n","  copying build/lib/pyspark/streaming/context.py -> build/bdist.linux-x86_64/wheel/pyspark/streaming\n","  copying build/lib/pyspark/streaming/util.py -> build/bdist.linux-x86_64/wheel/pyspark/streaming\n","  copying build/lib/pyspark/profiler.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/broadcast.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  creating build/bdist.linux-x86_64/wheel/pyspark/pandas/spark\n","  copying build/lib/pyspark/pandas/spark/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/spark\n","  copying build/lib/pyspark/pandas/spark/utils.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/spark\n","  copying build/lib/pyspark/pandas/spark/functions.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/spark\n","  copying build/lib/pyspark/pandas/spark/accessors.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/spark\n","  copying build/lib/pyspark/pandas/frame.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  creating build/bdist.linux-x86_64/wheel/pyspark/pandas/typedef\n","  copying build/lib/pyspark/pandas/typedef/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/typedef\n","  copying build/lib/pyspark/pandas/typedef/typehints.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/typedef\n","  copying build/lib/pyspark/pandas/exceptions.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  creating build/bdist.linux-x86_64/wheel/pyspark/pandas/indexes\n","  copying build/lib/pyspark/pandas/indexes/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/indexes\n","  copying build/lib/pyspark/pandas/indexes/numeric.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/indexes\n","  copying build/lib/pyspark/pandas/indexes/category.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/indexes\n","  copying build/lib/pyspark/pandas/indexes/multi.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/indexes\n","  copying build/lib/pyspark/pandas/indexes/base.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/indexes\n","  copying build/lib/pyspark/pandas/indexes/datetimes.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/indexes\n","  copying build/lib/pyspark/pandas/indexes/timedelta.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/indexes\n","  copying build/lib/pyspark/pandas/internal.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/supported_api_gen.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/strings.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/namespace.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  creating build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/date_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/binary_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/boolean_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/string_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/null_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/datetime_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/timedelta_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/categorical_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/base.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/udt_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/complex_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  copying build/lib/pyspark/pandas/data_type_ops/num_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/data_type_ops\n","  creating build/bdist.linux-x86_64/wheel/pyspark/pandas/usage_logging\n","  copying build/lib/pyspark/pandas/usage_logging/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/usage_logging\n","  copying build/lib/pyspark/pandas/usage_logging/usage_logger.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/usage_logging\n","  copying build/lib/pyspark/pandas/mlflow.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/categorical.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/sql_formatter.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/window.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/numpy_compat.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/resample.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/utils.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/extensions.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/_typing.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/generic.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/correlation.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/indexing.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/config.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/groupby.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/base.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/datetimes.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/series.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/pandas/accessors.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  creating build/bdist.linux-x86_64/wheel/pyspark/pandas/plot\n","  copying build/lib/pyspark/pandas/plot/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/plot\n","  copying build/lib/pyspark/pandas/plot/core.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/plot\n","  copying build/lib/pyspark/pandas/plot/plotly.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/plot\n","  copying build/lib/pyspark/pandas/plot/matplotlib.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/plot\n","  creating build/bdist.linux-x86_64/wheel/pyspark/pandas/missing\n","  copying build/lib/pyspark/pandas/missing/frame.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/missing\n","  copying build/lib/pyspark/pandas/missing/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/missing\n","  copying build/lib/pyspark/pandas/missing/scalars.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/missing\n","  copying build/lib/pyspark/pandas/missing/common.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/missing\n","  copying build/lib/pyspark/pandas/missing/indexes.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/missing\n","  copying build/lib/pyspark/pandas/missing/general_functions.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/missing\n","  copying build/lib/pyspark/pandas/missing/window.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/missing\n","  copying build/lib/pyspark/pandas/missing/resample.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/missing\n","  copying build/lib/pyspark/pandas/missing/groupby.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/missing\n","  copying build/lib/pyspark/pandas/missing/series.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas/missing\n","  copying build/lib/pyspark/pandas/sql_processor.py -> build/bdist.linux-x86_64/wheel/pyspark/pandas\n","  copying build/lib/pyspark/accumulators.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/worker.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/mllib/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/mllib/common.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  creating build/bdist.linux-x86_64/wheel/pyspark/mllib/linalg\n","  copying build/lib/pyspark/mllib/linalg/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib/linalg\n","  copying build/lib/pyspark/mllib/linalg/distributed.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib/linalg\n","  copying build/lib/pyspark/mllib/_typing.pyi -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/mllib/feature.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/mllib/tree.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/mllib/classification.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/mllib/regression.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/mllib/random.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/mllib/clustering.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  creating build/bdist.linux-x86_64/wheel/pyspark/mllib/stat\n","  copying build/lib/pyspark/mllib/stat/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib/stat\n","  copying build/lib/pyspark/mllib/stat/distribution.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib/stat\n","  copying build/lib/pyspark/mllib/stat/test.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib/stat\n","  copying build/lib/pyspark/mllib/stat/_statistics.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib/stat\n","  copying build/lib/pyspark/mllib/stat/KernelDensity.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib/stat\n","  copying build/lib/pyspark/mllib/recommendation.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/mllib/evaluation.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/mllib/fpm.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/mllib/util.py -> build/bdist.linux-x86_64/wheel/pyspark/mllib\n","  copying build/lib/pyspark/taskcontext.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/java_gateway.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/install.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/serializers.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/errors\n","  copying build/lib/pyspark/errors/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/errors\n","  creating build/bdist.linux-x86_64/wheel/pyspark/errors/exceptions\n","  copying build/lib/pyspark/errors/exceptions/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/errors/exceptions\n","  copying build/lib/pyspark/errors/exceptions/connect.py -> build/bdist.linux-x86_64/wheel/pyspark/errors/exceptions\n","  copying build/lib/pyspark/errors/exceptions/captured.py -> build/bdist.linux-x86_64/wheel/pyspark/errors/exceptions\n","  copying build/lib/pyspark/errors/exceptions/base.py -> build/bdist.linux-x86_64/wheel/pyspark/errors/exceptions\n","  copying build/lib/pyspark/errors/utils.py -> build/bdist.linux-x86_64/wheel/pyspark/errors\n","  copying build/lib/pyspark/errors/error_classes.py -> build/bdist.linux-x86_64/wheel/pyspark/errors\n","  copying build/lib/pyspark/shuffle.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/resource\n","  copying build/lib/pyspark/resource/information.py -> build/bdist.linux-x86_64/wheel/pyspark/resource\n","  copying build/lib/pyspark/resource/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/resource\n","  copying build/lib/pyspark/resource/requests.py -> build/bdist.linux-x86_64/wheel/pyspark/resource\n","  copying build/lib/pyspark/resource/profile.py -> build/bdist.linux-x86_64/wheel/pyspark/resource\n","  copying build/lib/pyspark/context.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/resultiterable.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/session.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/group.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  creating build/bdist.linux-x86_64/wheel/pyspark/sql/avro\n","  copying build/lib/pyspark/sql/avro/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/avro\n","  copying build/lib/pyspark/sql/avro/functions.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/avro\n","  copying build/lib/pyspark/sql/conf.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/_typing.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/observation.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  creating build/bdist.linux-x86_64/wheel/pyspark/sql/streaming\n","  copying build/lib/pyspark/sql/streaming/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/streaming\n","  copying build/lib/pyspark/sql/streaming/listener.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/streaming\n","  copying build/lib/pyspark/sql/streaming/state.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/streaming\n","  copying build/lib/pyspark/sql/streaming/readwriter.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/streaming\n","  copying build/lib/pyspark/sql/streaming/query.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/streaming\n","  creating build/bdist.linux-x86_64/wheel/pyspark/sql/pandas\n","  copying build/lib/pyspark/sql/pandas/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas\n","  copying build/lib/pyspark/sql/pandas/map_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas\n","  copying build/lib/pyspark/sql/pandas/utils.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas\n","  copying build/lib/pyspark/sql/pandas/serializers.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas\n","  copying build/lib/pyspark/sql/pandas/conversion.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas\n","  copying build/lib/pyspark/sql/pandas/types.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas\n","  copying build/lib/pyspark/sql/pandas/group_ops.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas\n","  copying build/lib/pyspark/sql/pandas/functions.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas\n","  copying build/lib/pyspark/sql/pandas/typehints.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas\n","  copying build/lib/pyspark/sql/pandas/functions.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas\n","  creating build/bdist.linux-x86_64/wheel/pyspark/sql/pandas/_typing\n","  creating build/bdist.linux-x86_64/wheel/pyspark/sql/pandas/_typing/protocols\n","  copying build/lib/pyspark/sql/pandas/_typing/protocols/frame.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas/_typing/protocols\n","  copying build/lib/pyspark/sql/pandas/_typing/protocols/series.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas/_typing/protocols\n","  copying build/lib/pyspark/sql/pandas/_typing/protocols/__init__.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas/_typing/protocols\n","  copying build/lib/pyspark/sql/pandas/_typing/__init__.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/pandas/_typing\n","  copying build/lib/pyspark/sql/sql_formatter.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/window.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/utils.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/readwriter.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  creating build/bdist.linux-x86_64/wheel/pyspark/sql/protobuf\n","  copying build/lib/pyspark/sql/protobuf/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/protobuf\n","  copying build/lib/pyspark/sql/protobuf/functions.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/protobuf\n","  copying build/lib/pyspark/sql/dataframe.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  creating build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/session.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/client.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/plan.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/group.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/conf.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/expressions.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/window.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/utils.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/readwriter.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  creating build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/__init__.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/types_pb2.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/commands_pb2.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/base_pb2.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/example_plugins_pb2.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/relations_pb2.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/types_pb2.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/common_pb2.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/expressions_pb2.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/example_plugins_pb2.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/expressions_pb2.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/common_pb2.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/relations_pb2.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/catalog_pb2.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/catalog_pb2.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/base_pb2.pyi -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/base_pb2_grpc.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/proto/commands_pb2.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect/proto\n","  copying build/lib/pyspark/sql/connect/dataframe.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/_typing.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/conversion.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/types.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/catalog.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/functions.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/column.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/connect/udf.py -> build/bdist.linux-x86_64/wheel/pyspark/sql/connect\n","  copying build/lib/pyspark/sql/types.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/catalog.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/context.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/functions.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/column.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/sql/udf.py -> build/bdist.linux-x86_64/wheel/pyspark/sql\n","  copying build/lib/pyspark/daemon.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  copying build/lib/pyspark/join.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  creating build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/pyspark.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/beeline -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/load-spark-env.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-class2.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/find-spark-home -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-shell -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/find-spark-home.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/sparkR2.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-sql2.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/sparkR -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/docker-image-tool.sh -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/sparkR.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/run-example.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-class.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-shell.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-sql -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-sql.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-submit2.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/pyspark2.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-submit.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-submit -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/beeline.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-connect-shell -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/load-spark-env.sh -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-class -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/pyspark -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/spark-shell2.cmd -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/bin/run-example -> build/bdist.linux-x86_64/wheel/pyspark/bin\n","  copying build/lib/pyspark/util.py -> build/bdist.linux-x86_64/wheel/pyspark\n","  running install_egg_info\n","  Copying pyspark.egg-info to build/bdist.linux-x86_64/wheel/pyspark-3.4.1-py3.10.egg-info\n","  running install_scripts\n","  creating build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data\n","  creating build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/pyspark.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/beeline -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/load-spark-env.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-class2.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/find-spark-home -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-shell -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/find-spark-home.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/sparkR2.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-sql2.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/sparkR -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/docker-image-tool.sh -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/sparkR.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/find_spark_home.py -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/run-example.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-class.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-shell.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-sql -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-sql.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-submit2.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/pyspark2.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-submit.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-submit -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/beeline.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-connect-shell -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/load-spark-env.sh -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-class -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/pyspark -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/spark-shell2.cmd -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  copying build/scripts-3.10/run-example -> build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/pyspark.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/beeline to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/load-spark-env.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-class2.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/find-spark-home to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-shell to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/find-spark-home.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/sparkR2.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-sql2.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/sparkR to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/docker-image-tool.sh to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/sparkR.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/find_spark_home.py to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/run-example.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-class.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-shell.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-sql to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-sql.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-submit2.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/pyspark2.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-submit.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-submit to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/beeline.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-connect-shell to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/load-spark-env.sh to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-class to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/pyspark to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/spark-shell2.cmd to 755\n","  changing mode of build/bdist.linux-x86_64/wheel/pyspark-3.4.1.data/scripts/run-example to 755\n","  creating build/bdist.linux-x86_64/wheel/pyspark-3.4.1.dist-info/WHEEL\n","  creating '/tmp/pip-wheel-4ux8tbqr/pyspark-3.4.1-py2.py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n","  adding 'pyspark/__init__.py'\n","  adding 'pyspark/_globals.py'\n","  adding 'pyspark/_typing.pyi'\n","  adding 'pyspark/accumulators.py'\n","  adding 'pyspark/broadcast.py'\n","  adding 'pyspark/conf.py'\n","  adding 'pyspark/context.py'\n","  adding 'pyspark/daemon.py'\n","  adding 'pyspark/files.py'\n","  adding 'pyspark/find_spark_home.py'\n","  adding 'pyspark/install.py'\n","  adding 'pyspark/instrumentation_utils.py'\n","  adding 'pyspark/java_gateway.py'\n","  adding 'pyspark/join.py'\n","  adding 'pyspark/profiler.py'\n","  adding 'pyspark/py.typed'\n","  adding 'pyspark/rdd.py'\n","  adding 'pyspark/rddsampler.py'\n","  adding 'pyspark/resultiterable.py'\n","  adding 'pyspark/serializers.py'\n","  adding 'pyspark/shell.py'\n","  adding 'pyspark/shuffle.py'\n","  adding 'pyspark/statcounter.py'\n","  adding 'pyspark/status.py'\n","  adding 'pyspark/storagelevel.py'\n","  adding 'pyspark/taskcontext.py'\n","  adding 'pyspark/traceback_utils.py'\n","  adding 'pyspark/util.py'\n","  adding 'pyspark/version.py'\n","  adding 'pyspark/worker.py'\n","  adding 'pyspark/bin/beeline'\n","  adding 'pyspark/bin/beeline.cmd'\n","  adding 'pyspark/bin/docker-image-tool.sh'\n","  adding 'pyspark/bin/find-spark-home'\n","  adding 'pyspark/bin/find-spark-home.cmd'\n","  adding 'pyspark/bin/load-spark-env.cmd'\n","  adding 'pyspark/bin/load-spark-env.sh'\n","  adding 'pyspark/bin/pyspark'\n","  adding 'pyspark/bin/pyspark.cmd'\n","  adding 'pyspark/bin/pyspark2.cmd'\n","  adding 'pyspark/bin/run-example'\n","  adding 'pyspark/bin/run-example.cmd'\n","  adding 'pyspark/bin/spark-class'\n","  adding 'pyspark/bin/spark-class.cmd'\n","  adding 'pyspark/bin/spark-class2.cmd'\n","  adding 'pyspark/bin/spark-connect-shell'\n","  adding 'pyspark/bin/spark-shell'\n","  adding 'pyspark/bin/spark-shell.cmd'\n","  adding 'pyspark/bin/spark-shell2.cmd'\n","  adding 'pyspark/bin/spark-sql'\n","  adding 'pyspark/bin/spark-sql.cmd'\n","  adding 'pyspark/bin/spark-sql2.cmd'\n","  adding 'pyspark/bin/spark-submit'\n","  adding 'pyspark/bin/spark-submit.cmd'\n","  adding 'pyspark/bin/spark-submit2.cmd'\n","  adding 'pyspark/bin/sparkR'\n","  adding 'pyspark/bin/sparkR.cmd'\n","  adding 'pyspark/bin/sparkR2.cmd'\n","  adding 'pyspark/cloudpickle/__init__.py'\n","  adding 'pyspark/cloudpickle/cloudpickle.py'\n","  adding 'pyspark/cloudpickle/cloudpickle_fast.py'\n","  adding 'pyspark/cloudpickle/compat.py'\n","  adding 'pyspark/data/graphx/followers.txt'\n","  adding 'pyspark/data/graphx/users.txt'\n","  adding 'pyspark/data/mllib/gmm_data.txt'\n","  adding 'pyspark/data/mllib/kmeans_data.txt'\n","  adding 'pyspark/data/mllib/pagerank_data.txt'\n","  adding 'pyspark/data/mllib/pic_data.txt'\n","  adding 'pyspark/data/mllib/sample_binary_classification_data.txt'\n","  adding 'pyspark/data/mllib/sample_fpgrowth.txt'\n","  adding 'pyspark/data/mllib/sample_isotonic_regression_libsvm_data.txt'\n","  adding 'pyspark/data/mllib/sample_kmeans_data.txt'\n","  adding 'pyspark/data/mllib/sample_lda_data.txt'\n","  adding 'pyspark/data/mllib/sample_lda_libsvm_data.txt'\n","  adding 'pyspark/data/mllib/sample_libsvm_data.txt'\n","  adding 'pyspark/data/mllib/sample_linear_regression_data.txt'\n","  adding 'pyspark/data/mllib/sample_movielens_data.txt'\n","  adding 'pyspark/data/mllib/sample_multiclass_classification_data.txt'\n","  adding 'pyspark/data/mllib/sample_svm_data.txt'\n","  adding 'pyspark/data/mllib/streaming_kmeans_data_test.txt'\n","  adding 'pyspark/data/mllib/als/sample_movielens_ratings.txt'\n","  adding 'pyspark/data/mllib/als/test.data'\n","  adding 'pyspark/data/mllib/images/license.txt'\n","  adding 'pyspark/data/mllib/images/origin/license.txt'\n","  adding 'pyspark/data/mllib/images/origin/kittens/not-image.txt'\n","  adding 'pyspark/data/mllib/ridge-data/lpsa.data'\n","  adding 'pyspark/data/streaming/AFINN-111.txt'\n","  adding 'pyspark/errors/__init__.py'\n","  adding 'pyspark/errors/error_classes.py'\n","  adding 'pyspark/errors/utils.py'\n","  adding 'pyspark/errors/exceptions/__init__.py'\n","  adding 'pyspark/errors/exceptions/base.py'\n","  adding 'pyspark/errors/exceptions/captured.py'\n","  adding 'pyspark/errors/exceptions/connect.py'\n","  adding 'pyspark/examples/src/main/python/__init__.py'\n","  adding 'pyspark/examples/src/main/python/als.py'\n","  adding 'pyspark/examples/src/main/python/avro_inputformat.py'\n","  adding 'pyspark/examples/src/main/python/kmeans.py'\n","  adding 'pyspark/examples/src/main/python/logistic_regression.py'\n","  adding 'pyspark/examples/src/main/python/pagerank.py'\n","  adding 'pyspark/examples/src/main/python/parquet_inputformat.py'\n","  adding 'pyspark/examples/src/main/python/pi.py'\n","  adding 'pyspark/examples/src/main/python/sort.py'\n","  adding 'pyspark/examples/src/main/python/status_api_demo.py'\n","  adding 'pyspark/examples/src/main/python/transitive_closure.py'\n","  adding 'pyspark/examples/src/main/python/wordcount.py'\n","  adding 'pyspark/examples/src/main/python/ml/aft_survival_regression.py'\n","  adding 'pyspark/examples/src/main/python/ml/als_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/binarizer_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/bisecting_k_means_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/bucketizer_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/chi_square_test_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/chisq_selector_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/correlation_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/count_vectorizer_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/cross_validator.py'\n","  adding 'pyspark/examples/src/main/python/ml/dataframe_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/dct_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/decision_tree_classification_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/decision_tree_regression_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/elementwise_product_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/estimator_transformer_param_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/feature_hasher_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/fm_classifier_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/fm_regressor_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/fpgrowth_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/gaussian_mixture_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/generalized_linear_regression_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/imputer_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/index_to_string_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/interaction_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/isotonic_regression_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/kmeans_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/lda_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/linear_regression_with_elastic_net.py'\n","  adding 'pyspark/examples/src/main/python/ml/linearsvc.py'\n","  adding 'pyspark/examples/src/main/python/ml/logistic_regression_summary_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/logistic_regression_with_elastic_net.py'\n","  adding 'pyspark/examples/src/main/python/ml/max_abs_scaler_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/min_hash_lsh_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/min_max_scaler_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py'\n","  adding 'pyspark/examples/src/main/python/ml/multilayer_perceptron_classification.py'\n","  adding 'pyspark/examples/src/main/python/ml/n_gram_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/naive_bayes_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/normalizer_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/one_vs_rest_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/onehot_encoder_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/pca_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/pipeline_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/polynomial_expansion_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/power_iteration_clustering_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/prefixspan_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/quantile_discretizer_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/random_forest_classifier_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/random_forest_regressor_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/rformula_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/robust_scaler_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/sql_transformer.py'\n","  adding 'pyspark/examples/src/main/python/ml/standard_scaler_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/stopwords_remover_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/string_indexer_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/summarizer_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/tf_idf_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/tokenizer_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/train_validation_split.py'\n","  adding 'pyspark/examples/src/main/python/ml/univariate_feature_selector_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/variance_threshold_selector_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/vector_assembler_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/vector_indexer_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/vector_size_hint_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/vector_slicer_example.py'\n","  adding 'pyspark/examples/src/main/python/ml/word2vec_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/__init__.py'\n","  adding 'pyspark/examples/src/main/python/mllib/binary_classification_metrics_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/bisecting_k_means_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/correlations.py'\n","  adding 'pyspark/examples/src/main/python/mllib/correlations_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/decision_tree_classification_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/decision_tree_regression_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/elementwise_product_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/fpgrowth_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/gaussian_mixture_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/gaussian_mixture_model.py'\n","  adding 'pyspark/examples/src/main/python/mllib/gradient_boosting_classification_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/gradient_boosting_regression_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/hypothesis_testing_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/isotonic_regression_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/k_means_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/kernel_density_estimation_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/kmeans.py'\n","  adding 'pyspark/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/linear_regression_with_sgd_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/logistic_regression.py'\n","  adding 'pyspark/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/multi_class_metrics_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/multi_label_metrics_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/naive_bayes_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/normalizer_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/pca_rowmatrix_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/power_iteration_clustering_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/random_forest_classification_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/random_forest_regression_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/random_rdd_generation.py'\n","  adding 'pyspark/examples/src/main/python/mllib/ranking_metrics_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/recommendation_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/regression_metrics_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/sampled_rdds.py'\n","  adding 'pyspark/examples/src/main/python/mllib/standard_scaler_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/stratified_sampling_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/streaming_k_means_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/streaming_linear_regression_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/summary_statistics_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/svd_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/svm_with_sgd_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/tf_idf_example.py'\n","  adding 'pyspark/examples/src/main/python/mllib/word2vec.py'\n","  adding 'pyspark/examples/src/main/python/mllib/word2vec_example.py'\n","  adding 'pyspark/examples/src/main/python/sql/__init__.py'\n","  adding 'pyspark/examples/src/main/python/sql/arrow.py'\n","  adding 'pyspark/examples/src/main/python/sql/basic.py'\n","  adding 'pyspark/examples/src/main/python/sql/datasource.py'\n","  adding 'pyspark/examples/src/main/python/sql/hive.py'\n","  adding 'pyspark/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py'\n","  adding 'pyspark/examples/src/main/python/sql/streaming/structured_network_wordcount.py'\n","  adding 'pyspark/examples/src/main/python/sql/streaming/structured_network_wordcount_session_window.py'\n","  adding 'pyspark/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py'\n","  adding 'pyspark/examples/src/main/python/sql/streaming/structured_sessionization.py'\n","  adding 'pyspark/examples/src/main/python/streaming/__init__.py'\n","  adding 'pyspark/examples/src/main/python/streaming/hdfs_wordcount.py'\n","  adding 'pyspark/examples/src/main/python/streaming/network_wordcount.py'\n","  adding 'pyspark/examples/src/main/python/streaming/network_wordjoinsentiments.py'\n","  adding 'pyspark/examples/src/main/python/streaming/queue_stream.py'\n","  adding 'pyspark/examples/src/main/python/streaming/recoverable_network_wordcount.py'\n","  adding 'pyspark/examples/src/main/python/streaming/sql_network_wordcount.py'\n","  adding 'pyspark/examples/src/main/python/streaming/stateful_network_wordcount.py'\n","  adding 'pyspark/jars/HikariCP-2.5.1.jar'\n","  adding 'pyspark/jars/JLargeArrays-1.5.jar'\n","  adding 'pyspark/jars/JTransforms-3.1.jar'\n","  adding 'pyspark/jars/RoaringBitmap-0.9.38.jar'\n","  adding 'pyspark/jars/ST4-4.0.4.jar'\n","  adding 'pyspark/jars/activation-1.1.1.jar'\n","  adding 'pyspark/jars/aircompressor-0.21.jar'\n","  adding 'pyspark/jars/algebra_2.12-2.0.1.jar'\n","  adding 'pyspark/jars/annotations-17.0.0.jar'\n","  adding 'pyspark/jars/antlr-runtime-3.5.2.jar'\n","  adding 'pyspark/jars/antlr4-runtime-4.9.3.jar'\n","  adding 'pyspark/jars/aopalliance-repackaged-2.6.1.jar'\n","  adding 'pyspark/jars/arpack-3.0.3.jar'\n","  adding 'pyspark/jars/arpack_combined_all-0.1.jar'\n","  adding 'pyspark/jars/arrow-format-11.0.0.jar'\n","  adding 'pyspark/jars/arrow-memory-core-11.0.0.jar'\n","  adding 'pyspark/jars/arrow-memory-netty-11.0.0.jar'\n","  adding 'pyspark/jars/arrow-vector-11.0.0.jar'\n","  adding 'pyspark/jars/audience-annotations-0.5.0.jar'\n","  adding 'pyspark/jars/avro-1.11.1.jar'\n","  adding 'pyspark/jars/avro-ipc-1.11.1.jar'\n","  adding 'pyspark/jars/avro-mapred-1.11.1.jar'\n","  adding 'pyspark/jars/blas-3.0.3.jar'\n","  adding 'pyspark/jars/bonecp-0.8.0.RELEASE.jar'\n","  adding 'pyspark/jars/breeze-macros_2.12-2.1.0.jar'\n","  adding 'pyspark/jars/breeze_2.12-2.1.0.jar'\n","  adding 'pyspark/jars/cats-kernel_2.12-2.1.1.jar'\n","  adding 'pyspark/jars/chill-java-0.10.0.jar'\n","  adding 'pyspark/jars/chill_2.12-0.10.0.jar'\n","  adding 'pyspark/jars/commons-cli-1.5.0.jar'\n","  adding 'pyspark/jars/commons-codec-1.15.jar'\n","  adding 'pyspark/jars/commons-collections-3.2.2.jar'\n","  adding 'pyspark/jars/commons-collections4-4.4.jar'\n","  adding 'pyspark/jars/commons-compiler-3.1.9.jar'\n","  adding 'pyspark/jars/commons-compress-1.22.jar'\n","  adding 'pyspark/jars/commons-crypto-1.1.0.jar'\n","  adding 'pyspark/jars/commons-dbcp-1.4.jar'\n","  adding 'pyspark/jars/commons-io-2.11.0.jar'\n","  adding 'pyspark/jars/commons-lang-2.6.jar'\n","  adding 'pyspark/jars/commons-lang3-3.12.0.jar'\n","  adding 'pyspark/jars/commons-logging-1.1.3.jar'\n","  adding 'pyspark/jars/commons-math3-3.6.1.jar'\n","  adding 'pyspark/jars/commons-pool-1.5.4.jar'\n","  adding 'pyspark/jars/commons-text-1.10.0.jar'\n","  adding 'pyspark/jars/compress-lzf-1.1.2.jar'\n","  adding 'pyspark/jars/curator-client-2.13.0.jar'\n","  adding 'pyspark/jars/curator-framework-2.13.0.jar'\n","  adding 'pyspark/jars/curator-recipes-2.13.0.jar'\n","  adding 'pyspark/jars/datanucleus-api-jdo-4.2.4.jar'\n","  adding 'pyspark/jars/datanucleus-core-4.1.17.jar'\n","  adding 'pyspark/jars/datanucleus-rdbms-4.1.19.jar'\n","  adding 'pyspark/jars/derby-10.14.2.0.jar'\n","  adding 'pyspark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar'\n","  adding 'pyspark/jars/flatbuffers-java-1.12.0.jar'\n","  adding 'pyspark/jars/gson-2.2.4.jar'\n","  adding 'pyspark/jars/guava-14.0.1.jar'\n","  adding 'pyspark/jars/hadoop-client-api-3.3.4.jar'\n","  adding 'pyspark/jars/hadoop-client-runtime-3.3.4.jar'\n","  adding 'pyspark/jars/hadoop-shaded-guava-1.1.1.jar'\n","  adding 'pyspark/jars/hadoop-yarn-server-web-proxy-3.3.4.jar'\n","  adding 'pyspark/jars/hive-beeline-2.3.9.jar'\n","  adding 'pyspark/jars/hive-cli-2.3.9.jar'\n","  adding 'pyspark/jars/hive-common-2.3.9.jar'\n","  adding 'pyspark/jars/hive-exec-2.3.9-core.jar'\n","  adding 'pyspark/jars/hive-jdbc-2.3.9.jar'\n","  adding 'pyspark/jars/hive-llap-common-2.3.9.jar'\n","  adding 'pyspark/jars/hive-metastore-2.3.9.jar'\n","  adding 'pyspark/jars/hive-serde-2.3.9.jar'\n","  adding 'pyspark/jars/hive-service-rpc-3.1.3.jar'\n","  adding 'pyspark/jars/hive-shims-0.23-2.3.9.jar'\n","  adding 'pyspark/jars/hive-shims-2.3.9.jar'\n","  adding 'pyspark/jars/hive-shims-common-2.3.9.jar'\n","  adding 'pyspark/jars/hive-shims-scheduler-2.3.9.jar'\n","  adding 'pyspark/jars/hive-storage-api-2.8.1.jar'\n","  adding 'pyspark/jars/hk2-api-2.6.1.jar'\n","  adding 'pyspark/jars/hk2-locator-2.6.1.jar'\n","  adding 'pyspark/jars/hk2-utils-2.6.1.jar'\n","  adding 'pyspark/jars/httpclient-4.5.14.jar'\n","  adding 'pyspark/jars/httpcore-4.4.16.jar'\n","  adding 'pyspark/jars/istack-commons-runtime-3.0.8.jar'\n","  adding 'pyspark/jars/ivy-2.5.1.jar'\n","  adding 'pyspark/jars/jackson-annotations-2.14.2.jar'\n","  adding 'pyspark/jars/jackson-core-2.14.2.jar'\n","  adding 'pyspark/jars/jackson-core-asl-1.9.13.jar'\n","  adding 'pyspark/jars/jackson-databind-2.14.2.jar'\n","  adding 'pyspark/jars/jackson-dataformat-yaml-2.14.2.jar'\n","  adding 'pyspark/jars/jackson-datatype-jsr310-2.14.2.jar'\n","  adding 'pyspark/jars/jackson-mapper-asl-1.9.13.jar'\n","  adding 'pyspark/jars/jackson-module-scala_2.12-2.14.2.jar'\n","  adding 'pyspark/jars/jakarta.annotation-api-1.3.5.jar'\n","  adding 'pyspark/jars/jakarta.inject-2.6.1.jar'\n","  adding 'pyspark/jars/jakarta.servlet-api-4.0.3.jar'\n","  adding 'pyspark/jars/jakarta.validation-api-2.0.2.jar'\n","  adding 'pyspark/jars/jakarta.ws.rs-api-2.1.6.jar'\n","  adding 'pyspark/jars/jakarta.xml.bind-api-2.3.2.jar'\n","  adding 'pyspark/jars/janino-3.1.9.jar'\n","  adding 'pyspark/jars/javassist-3.25.0-GA.jar'\n","  adding 'pyspark/jars/javax.jdo-3.2.0-m3.jar'\n","  adding 'pyspark/jars/javolution-5.5.1.jar'\n","  adding 'pyspark/jars/jaxb-runtime-2.3.2.jar'\n","  adding 'pyspark/jars/jcl-over-slf4j-2.0.6.jar'\n","  adding 'pyspark/jars/jdo-api-3.0.1.jar'\n","  adding 'pyspark/jars/jersey-client-2.36.jar'\n","  adding 'pyspark/jars/jersey-common-2.36.jar'\n","  adding 'pyspark/jars/jersey-container-servlet-2.36.jar'\n","  adding 'pyspark/jars/jersey-container-servlet-core-2.36.jar'\n","  adding 'pyspark/jars/jersey-hk2-2.36.jar'\n","  adding 'pyspark/jars/jersey-server-2.36.jar'\n","  adding 'pyspark/jars/jline-2.14.6.jar'\n","  adding 'pyspark/jars/joda-time-2.12.2.jar'\n","  adding 'pyspark/jars/jodd-core-3.5.2.jar'\n","  adding 'pyspark/jars/jpam-1.1.jar'\n","  adding 'pyspark/jars/json-1.8.jar'\n","  adding 'pyspark/jars/json4s-ast_2.12-3.7.0-M11.jar'\n","  adding 'pyspark/jars/json4s-core_2.12-3.7.0-M11.jar'\n","  adding 'pyspark/jars/json4s-jackson_2.12-3.7.0-M11.jar'\n","  adding 'pyspark/jars/json4s-scalap_2.12-3.7.0-M11.jar'\n","  adding 'pyspark/jars/jsr305-3.0.0.jar'\n","  adding 'pyspark/jars/jta-1.1.jar'\n","  adding 'pyspark/jars/jul-to-slf4j-2.0.6.jar'\n","  adding 'pyspark/jars/kryo-shaded-4.0.2.jar'\n","  adding 'pyspark/jars/kubernetes-client-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-client-api-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-httpclient-okhttp-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-admissionregistration-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-apiextensions-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-apps-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-autoscaling-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-batch-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-certificates-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-common-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-coordination-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-core-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-discovery-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-events-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-extensions-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-flowcontrol-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-gatewayapi-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-metrics-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-networking-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-node-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-policy-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-rbac-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-scheduling-6.4.1.jar'\n","  adding 'pyspark/jars/kubernetes-model-storageclass-6.4.1.jar'\n","  adding 'pyspark/jars/lapack-3.0.3.jar'\n","  adding 'pyspark/jars/leveldbjni-all-1.8.jar'\n","  adding 'pyspark/jars/libfb303-0.9.3.jar'\n","  adding 'pyspark/jars/libthrift-0.12.0.jar'\n","  adding 'pyspark/jars/log4j-1.2-api-2.19.0.jar'\n","  adding 'pyspark/jars/log4j-api-2.19.0.jar'\n","  adding 'pyspark/jars/log4j-core-2.19.0.jar'\n","  adding 'pyspark/jars/log4j-slf4j2-impl-2.19.0.jar'\n","  adding 'pyspark/jars/logging-interceptor-3.12.12.jar'\n","  adding 'pyspark/jars/lz4-java-1.8.0.jar'\n","  adding 'pyspark/jars/mesos-1.4.3-shaded-protobuf.jar'\n","  adding 'pyspark/jars/metrics-core-4.2.15.jar'\n","  adding 'pyspark/jars/metrics-graphite-4.2.15.jar'\n","  adding 'pyspark/jars/metrics-jmx-4.2.15.jar'\n","  adding 'pyspark/jars/metrics-json-4.2.15.jar'\n","  adding 'pyspark/jars/metrics-jvm-4.2.15.jar'\n","  adding 'pyspark/jars/minlog-1.3.0.jar'\n","  adding 'pyspark/jars/netty-all-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-buffer-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-codec-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-codec-http-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-codec-http2-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-codec-socks-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-common-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-handler-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-handler-proxy-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-resolver-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-transport-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-transport-classes-epoll-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-transport-classes-kqueue-4.1.87.Final.jar'\n","  adding 'pyspark/jars/netty-transport-native-epoll-4.1.87.Final-linux-aarch_64.jar'\n","  adding 'pyspark/jars/netty-transport-native-epoll-4.1.87.Final-linux-x86_64.jar'\n","  adding 'pyspark/jars/netty-transport-native-kqueue-4.1.87.Final-osx-aarch_64.jar'\n","  adding 'pyspark/jars/netty-transport-native-kqueue-4.1.87.Final-osx-x86_64.jar'\n","  adding 'pyspark/jars/netty-transport-native-unix-common-4.1.87.Final.jar'\n","  adding 'pyspark/jars/objenesis-3.2.jar'\n","  adding 'pyspark/jars/okhttp-3.12.12.jar'\n","  adding 'pyspark/jars/okio-1.15.0.jar'\n","  adding 'pyspark/jars/opencsv-2.3.jar'\n","  adding 'pyspark/jars/orc-core-1.8.4-shaded-protobuf.jar'\n","  adding 'pyspark/jars/orc-mapreduce-1.8.4-shaded-protobuf.jar'\n","  adding 'pyspark/jars/orc-shims-1.8.4.jar'\n","  adding 'pyspark/jars/oro-2.0.8.jar'\n","  adding 'pyspark/jars/osgi-resource-locator-1.0.3.jar'\n","  adding 'pyspark/jars/paranamer-2.8.jar'\n","  adding 'pyspark/jars/parquet-column-1.12.3.jar'\n","  adding 'pyspark/jars/parquet-common-1.12.3.jar'\n","  adding 'pyspark/jars/parquet-encoding-1.12.3.jar'\n","  adding 'pyspark/jars/parquet-format-structures-1.12.3.jar'\n","  adding 'pyspark/jars/parquet-hadoop-1.12.3.jar'\n","  adding 'pyspark/jars/parquet-jackson-1.12.3.jar'\n","  adding 'pyspark/jars/pickle-1.3.jar'\n","  adding 'pyspark/jars/protobuf-java-2.5.0.jar'\n","  adding 'pyspark/jars/py4j-0.10.9.7.jar'\n","  adding 'pyspark/jars/rocksdbjni-7.9.2.jar'\n","  adding 'pyspark/jars/scala-collection-compat_2.12-2.7.0.jar'\n","  adding 'pyspark/jars/scala-compiler-2.12.17.jar'\n","  adding 'pyspark/jars/scala-library-2.12.17.jar'\n","  adding 'pyspark/jars/scala-parser-combinators_2.12-2.1.1.jar'\n","  adding 'pyspark/jars/scala-reflect-2.12.17.jar'\n","  adding 'pyspark/jars/scala-xml_2.12-2.1.0.jar'\n","  adding 'pyspark/jars/shims-0.9.38.jar'\n","  adding 'pyspark/jars/slf4j-api-2.0.6.jar'\n","  adding 'pyspark/jars/snakeyaml-1.33.jar'\n","  adding 'pyspark/jars/snappy-java-1.1.10.1.jar'\n","  adding 'pyspark/jars/spark-catalyst_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-core_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-graphx_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-hive-thriftserver_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-hive_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-kubernetes_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-kvstore_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-launcher_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-mesos_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-mllib-local_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-mllib_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-network-common_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-network-shuffle_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-repl_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-sketch_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-sql_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-streaming_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-tags_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-unsafe_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spark-yarn_2.12-3.4.1.jar'\n","  adding 'pyspark/jars/spire-macros_2.12-0.17.0.jar'\n","  adding 'pyspark/jars/spire-platform_2.12-0.17.0.jar'\n","  adding 'pyspark/jars/spire-util_2.12-0.17.0.jar'\n","  adding 'pyspark/jars/spire_2.12-0.17.0.jar'\n","  adding 'pyspark/jars/stax-api-1.0.1.jar'\n","  adding 'pyspark/jars/stream-2.9.6.jar'\n","  adding 'pyspark/jars/super-csv-2.2.0.jar'\n","  adding 'pyspark/jars/threeten-extra-1.7.1.jar'\n","  adding 'pyspark/jars/tink-1.7.0.jar'\n","  adding 'pyspark/jars/transaction-api-1.1.jar'\n","  adding 'pyspark/jars/univocity-parsers-2.9.1.jar'\n","  adding 'pyspark/jars/xbean-asm9-shaded-4.22.jar'\n","  adding 'pyspark/jars/xz-1.9.jar'\n","  adding 'pyspark/jars/zjsonpatch-0.3.0.jar'\n","  adding 'pyspark/jars/zookeeper-3.6.3.jar'\n","  adding 'pyspark/jars/zookeeper-jute-3.6.3.jar'\n","  adding 'pyspark/jars/zstd-jni-1.5.2-5.jar'\n","  adding 'pyspark/licenses/LICENSE-AnchorJS.txt'\n","  adding 'pyspark/licenses/LICENSE-CC0.txt'\n","  adding 'pyspark/licenses/LICENSE-bootstrap.txt'\n","  adding 'pyspark/licenses/LICENSE-cloudpickle.txt'\n","  adding 'pyspark/licenses/LICENSE-copybutton.txt'\n","  adding 'pyspark/licenses/LICENSE-d3.min.js.txt'\n","  adding 'pyspark/licenses/LICENSE-dagre-d3.txt'\n","  adding 'pyspark/licenses/LICENSE-datatables.txt'\n","  adding 'pyspark/licenses/LICENSE-graphlib-dot.txt'\n","  adding 'pyspark/licenses/LICENSE-jdom.txt'\n","  adding 'pyspark/licenses/LICENSE-join.txt'\n","  adding 'pyspark/licenses/LICENSE-jquery.txt'\n","  adding 'pyspark/licenses/LICENSE-json-formatter.txt'\n","  adding 'pyspark/licenses/LICENSE-matchMedia-polyfill.txt'\n","  adding 'pyspark/licenses/LICENSE-modernizr.txt'\n","  adding 'pyspark/licenses/LICENSE-mustache.txt'\n","  adding 'pyspark/licenses/LICENSE-py4j.txt'\n","  adding 'pyspark/licenses/LICENSE-respond.txt'\n","  adding 'pyspark/licenses/LICENSE-sbt-launch-lib.txt'\n","  adding 'pyspark/licenses/LICENSE-sorttable.js.txt'\n","  adding 'pyspark/licenses/LICENSE-vis-timeline.txt'\n","  adding 'pyspark/ml/__init__.py'\n","  adding 'pyspark/ml/_typing.pyi'\n","  adding 'pyspark/ml/base.py'\n","  adding 'pyspark/ml/classification.py'\n","  adding 'pyspark/ml/clustering.py'\n","  adding 'pyspark/ml/common.py'\n","  adding 'pyspark/ml/evaluation.py'\n","  adding 'pyspark/ml/feature.py'\n","  adding 'pyspark/ml/fpm.py'\n","  adding 'pyspark/ml/functions.py'\n","  adding 'pyspark/ml/image.py'\n","  adding 'pyspark/ml/model_cache.py'\n","  adding 'pyspark/ml/pipeline.py'\n","  adding 'pyspark/ml/recommendation.py'\n","  adding 'pyspark/ml/regression.py'\n","  adding 'pyspark/ml/stat.py'\n","  adding 'pyspark/ml/tree.py'\n","  adding 'pyspark/ml/tuning.py'\n","  adding 'pyspark/ml/util.py'\n","  adding 'pyspark/ml/wrapper.py'\n","  adding 'pyspark/ml/linalg/__init__.py'\n","  adding 'pyspark/ml/param/__init__.py'\n","  adding 'pyspark/ml/param/_shared_params_code_gen.py'\n","  adding 'pyspark/ml/param/shared.py'\n","  adding 'pyspark/ml/torch/__init__.py'\n","  adding 'pyspark/ml/torch/distributor.py'\n","  adding 'pyspark/ml/torch/log_communication.py'\n","  adding 'pyspark/ml/torch/torch_run_process_wrapper.py'\n","  adding 'pyspark/mllib/__init__.py'\n","  adding 'pyspark/mllib/_typing.pyi'\n","  adding 'pyspark/mllib/classification.py'\n","  adding 'pyspark/mllib/clustering.py'\n","  adding 'pyspark/mllib/common.py'\n","  adding 'pyspark/mllib/evaluation.py'\n","  adding 'pyspark/mllib/feature.py'\n","  adding 'pyspark/mllib/fpm.py'\n","  adding 'pyspark/mllib/random.py'\n","  adding 'pyspark/mllib/recommendation.py'\n","  adding 'pyspark/mllib/regression.py'\n","  adding 'pyspark/mllib/tree.py'\n","  adding 'pyspark/mllib/util.py'\n","  adding 'pyspark/mllib/linalg/__init__.py'\n","  adding 'pyspark/mllib/linalg/distributed.py'\n","  adding 'pyspark/mllib/stat/KernelDensity.py'\n","  adding 'pyspark/mllib/stat/__init__.py'\n","  adding 'pyspark/mllib/stat/_statistics.py'\n","  adding 'pyspark/mllib/stat/distribution.py'\n","  adding 'pyspark/mllib/stat/test.py'\n","  adding 'pyspark/pandas/__init__.py'\n","  adding 'pyspark/pandas/_typing.py'\n","  adding 'pyspark/pandas/accessors.py'\n","  adding 'pyspark/pandas/base.py'\n","  adding 'pyspark/pandas/categorical.py'\n","  adding 'pyspark/pandas/config.py'\n","  adding 'pyspark/pandas/correlation.py'\n","  adding 'pyspark/pandas/datetimes.py'\n","  adding 'pyspark/pandas/exceptions.py'\n","  adding 'pyspark/pandas/extensions.py'\n","  adding 'pyspark/pandas/frame.py'\n","  adding 'pyspark/pandas/generic.py'\n","  adding 'pyspark/pandas/groupby.py'\n","  adding 'pyspark/pandas/indexing.py'\n","  adding 'pyspark/pandas/internal.py'\n","  adding 'pyspark/pandas/mlflow.py'\n","  adding 'pyspark/pandas/namespace.py'\n","  adding 'pyspark/pandas/numpy_compat.py'\n","  adding 'pyspark/pandas/resample.py'\n","  adding 'pyspark/pandas/series.py'\n","  adding 'pyspark/pandas/sql_formatter.py'\n","  adding 'pyspark/pandas/sql_processor.py'\n","  adding 'pyspark/pandas/strings.py'\n","  adding 'pyspark/pandas/supported_api_gen.py'\n","  adding 'pyspark/pandas/utils.py'\n","  adding 'pyspark/pandas/window.py'\n","  adding 'pyspark/pandas/data_type_ops/__init__.py'\n","  adding 'pyspark/pandas/data_type_ops/base.py'\n","  adding 'pyspark/pandas/data_type_ops/binary_ops.py'\n","  adding 'pyspark/pandas/data_type_ops/boolean_ops.py'\n","  adding 'pyspark/pandas/data_type_ops/categorical_ops.py'\n","  adding 'pyspark/pandas/data_type_ops/complex_ops.py'\n","  adding 'pyspark/pandas/data_type_ops/date_ops.py'\n","  adding 'pyspark/pandas/data_type_ops/datetime_ops.py'\n","  adding 'pyspark/pandas/data_type_ops/null_ops.py'\n","  adding 'pyspark/pandas/data_type_ops/num_ops.py'\n","  adding 'pyspark/pandas/data_type_ops/string_ops.py'\n","  adding 'pyspark/pandas/data_type_ops/timedelta_ops.py'\n","  adding 'pyspark/pandas/data_type_ops/udt_ops.py'\n","  adding 'pyspark/pandas/indexes/__init__.py'\n","  adding 'pyspark/pandas/indexes/base.py'\n","  adding 'pyspark/pandas/indexes/category.py'\n","  adding 'pyspark/pandas/indexes/datetimes.py'\n","  adding 'pyspark/pandas/indexes/multi.py'\n","  adding 'pyspark/pandas/indexes/numeric.py'\n","  adding 'pyspark/pandas/indexes/timedelta.py'\n","  adding 'pyspark/pandas/missing/__init__.py'\n","  adding 'pyspark/pandas/missing/common.py'\n","  adding 'pyspark/pandas/missing/frame.py'\n","  adding 'pyspark/pandas/missing/general_functions.py'\n","  adding 'pyspark/pandas/missing/groupby.py'\n","  adding 'pyspark/pandas/missing/indexes.py'\n","  adding 'pyspark/pandas/missing/resample.py'\n","  adding 'pyspark/pandas/missing/scalars.py'\n","  adding 'pyspark/pandas/missing/series.py'\n","  adding 'pyspark/pandas/missing/window.py'\n","  adding 'pyspark/pandas/plot/__init__.py'\n","  adding 'pyspark/pandas/plot/core.py'\n","  adding 'pyspark/pandas/plot/matplotlib.py'\n","  adding 'pyspark/pandas/plot/plotly.py'\n","  adding 'pyspark/pandas/spark/__init__.py'\n","  adding 'pyspark/pandas/spark/accessors.py'\n","  adding 'pyspark/pandas/spark/functions.py'\n","  adding 'pyspark/pandas/spark/utils.py'\n","  adding 'pyspark/pandas/typedef/__init__.py'\n","  adding 'pyspark/pandas/typedef/typehints.py'\n","  adding 'pyspark/pandas/usage_logging/__init__.py'\n","  adding 'pyspark/pandas/usage_logging/usage_logger.py'\n","  adding 'pyspark/python/lib/py4j-0.10.9.7-src.zip'\n","  adding 'pyspark/python/lib/pyspark.zip'\n","  adding 'pyspark/python/pyspark/shell.py'\n","  adding 'pyspark/resource/__init__.py'\n","  adding 'pyspark/resource/information.py'\n","  adding 'pyspark/resource/profile.py'\n","  adding 'pyspark/resource/requests.py'\n","  adding 'pyspark/sbin/spark-config.sh'\n","  adding 'pyspark/sbin/spark-daemon.sh'\n","  adding 'pyspark/sbin/start-history-server.sh'\n","  adding 'pyspark/sbin/stop-history-server.sh'\n","  adding 'pyspark/sql/__init__.py'\n","  adding 'pyspark/sql/_typing.pyi'\n","  adding 'pyspark/sql/catalog.py'\n","  adding 'pyspark/sql/column.py'\n","  adding 'pyspark/sql/conf.py'\n","  adding 'pyspark/sql/context.py'\n","  adding 'pyspark/sql/dataframe.py'\n","  adding 'pyspark/sql/functions.py'\n","  adding 'pyspark/sql/group.py'\n","  adding 'pyspark/sql/observation.py'\n","  adding 'pyspark/sql/readwriter.py'\n","  adding 'pyspark/sql/session.py'\n","  adding 'pyspark/sql/sql_formatter.py'\n","  adding 'pyspark/sql/types.py'\n","  adding 'pyspark/sql/udf.py'\n","  adding 'pyspark/sql/utils.py'\n","  adding 'pyspark/sql/window.py'\n","  adding 'pyspark/sql/avro/__init__.py'\n","  adding 'pyspark/sql/avro/functions.py'\n","  adding 'pyspark/sql/connect/__init__.py'\n","  adding 'pyspark/sql/connect/_typing.py'\n","  adding 'pyspark/sql/connect/catalog.py'\n","  adding 'pyspark/sql/connect/client.py'\n","  adding 'pyspark/sql/connect/column.py'\n","  adding 'pyspark/sql/connect/conf.py'\n","  adding 'pyspark/sql/connect/conversion.py'\n","  adding 'pyspark/sql/connect/dataframe.py'\n","  adding 'pyspark/sql/connect/expressions.py'\n","  adding 'pyspark/sql/connect/functions.py'\n","  adding 'pyspark/sql/connect/group.py'\n","  adding 'pyspark/sql/connect/plan.py'\n","  adding 'pyspark/sql/connect/readwriter.py'\n","  adding 'pyspark/sql/connect/session.py'\n","  adding 'pyspark/sql/connect/types.py'\n","  adding 'pyspark/sql/connect/udf.py'\n","  adding 'pyspark/sql/connect/utils.py'\n","  adding 'pyspark/sql/connect/window.py'\n","  adding 'pyspark/sql/connect/proto/__init__.py'\n","  adding 'pyspark/sql/connect/proto/base_pb2.py'\n","  adding 'pyspark/sql/connect/proto/base_pb2.pyi'\n","  adding 'pyspark/sql/connect/proto/base_pb2_grpc.py'\n","  adding 'pyspark/sql/connect/proto/catalog_pb2.py'\n","  adding 'pyspark/sql/connect/proto/catalog_pb2.pyi'\n","  adding 'pyspark/sql/connect/proto/commands_pb2.py'\n","  adding 'pyspark/sql/connect/proto/commands_pb2.pyi'\n","  adding 'pyspark/sql/connect/proto/common_pb2.py'\n","  adding 'pyspark/sql/connect/proto/common_pb2.pyi'\n","  adding 'pyspark/sql/connect/proto/example_plugins_pb2.py'\n","  adding 'pyspark/sql/connect/proto/example_plugins_pb2.pyi'\n","  adding 'pyspark/sql/connect/proto/expressions_pb2.py'\n","  adding 'pyspark/sql/connect/proto/expressions_pb2.pyi'\n","  adding 'pyspark/sql/connect/proto/relations_pb2.py'\n","  adding 'pyspark/sql/connect/proto/relations_pb2.pyi'\n","  adding 'pyspark/sql/connect/proto/types_pb2.py'\n","  adding 'pyspark/sql/connect/proto/types_pb2.pyi'\n","  adding 'pyspark/sql/pandas/__init__.py'\n","  adding 'pyspark/sql/pandas/conversion.py'\n","  adding 'pyspark/sql/pandas/functions.py'\n","  adding 'pyspark/sql/pandas/functions.pyi'\n","  adding 'pyspark/sql/pandas/group_ops.py'\n","  adding 'pyspark/sql/pandas/map_ops.py'\n","  adding 'pyspark/sql/pandas/serializers.py'\n","  adding 'pyspark/sql/pandas/typehints.py'\n","  adding 'pyspark/sql/pandas/types.py'\n","  adding 'pyspark/sql/pandas/utils.py'\n","  adding 'pyspark/sql/pandas/_typing/__init__.pyi'\n","  adding 'pyspark/sql/pandas/_typing/protocols/__init__.pyi'\n","  adding 'pyspark/sql/pandas/_typing/protocols/frame.pyi'\n","  adding 'pyspark/sql/pandas/_typing/protocols/series.pyi'\n","  adding 'pyspark/sql/protobuf/__init__.py'\n","  adding 'pyspark/sql/protobuf/functions.py'\n","  adding 'pyspark/sql/streaming/__init__.py'\n","  adding 'pyspark/sql/streaming/listener.py'\n","  adding 'pyspark/sql/streaming/query.py'\n","  adding 'pyspark/sql/streaming/readwriter.py'\n","  adding 'pyspark/sql/streaming/state.py'\n","  adding 'pyspark/streaming/__init__.py'\n","  adding 'pyspark/streaming/context.py'\n","  adding 'pyspark/streaming/dstream.py'\n","  adding 'pyspark/streaming/kinesis.py'\n","  adding 'pyspark/streaming/listener.py'\n","  adding 'pyspark/streaming/util.py'\n","  adding 'pyspark-3.4.1.data/scripts/beeline'\n","  adding 'pyspark-3.4.1.data/scripts/beeline.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/docker-image-tool.sh'\n","  adding 'pyspark-3.4.1.data/scripts/find-spark-home'\n","  adding 'pyspark-3.4.1.data/scripts/find-spark-home.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/find_spark_home.py'\n","  adding 'pyspark-3.4.1.data/scripts/load-spark-env.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/load-spark-env.sh'\n","  adding 'pyspark-3.4.1.data/scripts/pyspark'\n","  adding 'pyspark-3.4.1.data/scripts/pyspark.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/pyspark2.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/run-example'\n","  adding 'pyspark-3.4.1.data/scripts/run-example.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/spark-class'\n","  adding 'pyspark-3.4.1.data/scripts/spark-class.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/spark-class2.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/spark-connect-shell'\n","  adding 'pyspark-3.4.1.data/scripts/spark-shell'\n","  adding 'pyspark-3.4.1.data/scripts/spark-shell.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/spark-shell2.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/spark-sql'\n","  adding 'pyspark-3.4.1.data/scripts/spark-sql.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/spark-sql2.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/spark-submit'\n","  adding 'pyspark-3.4.1.data/scripts/spark-submit.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/spark-submit2.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/sparkR'\n","  adding 'pyspark-3.4.1.data/scripts/sparkR.cmd'\n","  adding 'pyspark-3.4.1.data/scripts/sparkR2.cmd'\n","  adding 'pyspark-3.4.1.dist-info/METADATA'\n","  adding 'pyspark-3.4.1.dist-info/WHEEL'\n","  adding 'pyspark-3.4.1.dist-info/top_level.txt'\n","  adding 'pyspark-3.4.1.dist-info/RECORD'\n","  removing build/bdist.linux-x86_64/wheel\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=c01c2a0cdf149f393a3ef71f569baf63905c8f1890cecb96132dd27791e83dcc\n","  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.4.1\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{"id":"43atdPIVBWRF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark = SparkSession.builder.appName(\"Load-json-to-pyspark-dataframe\").getOrCreate()"],"metadata":{"id":"VEfWBVEnBfZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["review = spark.read.option(\"lines\",\"true\").option(\"mode\", \"PERMISSIVE\").json('/content/drive/MyDrive/Final Project /Yelp/review.json')"],"metadata":{"id":"jsLR5WoVBkcF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pasar la base de datos a formato parquet"],"metadata":{"id":"usyKeEpfBxH-"}},{"cell_type":"code","source":["review = review.repartition(10)\n","review.write.format('parquet').save('/content/drive/MyDrive/Final Project /Yelp/review.parquet')"],"metadata":{"id":"oYyRC0jOBwyg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def concatenar_archivos_parquet(ruta_base):\n","    lista_archivos = glob.glob(ruta_base + \"part-*.parquet\")\n","    lista_df = []\n","    for ruta_archivo in lista_archivos:\n","        archivo = pd.read_parquet(ruta_archivo)\n","        lista_df.append(archivo)\n","    df_concatenado = pd.concat(lista_df)\n","    return df_concatenado"],"metadata":{"id":"DCButdt8FlKF","executionInfo":{"status":"ok","timestamp":1695154620078,"user_tz":240,"elapsed":228,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["ruta_base = \"/content/drive/MyDrive/Final Project /Yelp/review.parquet/\"\n","\n","df_concatenado = concatenar_archivos_parquet(ruta_base)"],"metadata":{"id":"j_ACFDf5Fs7r","executionInfo":{"status":"ok","timestamp":1695154761411,"user_tz":240,"elapsed":94096,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Dimensión de la base de datos"],"metadata":{"id":"RND9vuqjGcM7"}},{"cell_type":"code","source":["df_concatenado.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S262UecPGXAK","executionInfo":{"status":"ok","timestamp":1695154813832,"user_tz":240,"elapsed":197,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"610c54a4-1ab1-4ac4-a18a-d6f8d6edab32"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6990280, 9)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["Buscar solo los registros que contengan palabras afines al analisis"],"metadata":{"id":"bFKig8d8Gleh"}},{"cell_type":"code","source":["palabras = [\"meat\", \"roast\", \"beef\", \"steak\"]\n","mascara = df_concatenado['text'].str.contains('|'.join(palabras))\n","df_final = df_concatenado[mascara]"],"metadata":{"id":"-aNTubgrGi3m","executionInfo":{"status":"ok","timestamp":1695154926414,"user_tz":240,"elapsed":58840,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["Dimension del dataframe final"],"metadata":{"id":"1xQzf2DBGwQx"}},{"cell_type":"code","source":["df_final.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2bNmKlo5GxFT","executionInfo":{"status":"ok","timestamp":1695154942585,"user_tz":240,"elapsed":194,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"ed0ae59f-fb69-474e-b2ee-a7133ca65175"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(740028, 9)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["Valores nulos e informacion general"],"metadata":{"id":"8P-DyCloG3Gv"}},{"cell_type":"code","source":["df_final.isna().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vt2qKw3vG5RI","executionInfo":{"status":"ok","timestamp":1695154940816,"user_tz":240,"elapsed":1069,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"661f68ef-8f4a-494f-f105-dbd30f73fa73"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["business_id    0\n","cool           0\n","date           0\n","funny          0\n","review_id      0\n","stars          0\n","text           0\n","useful         0\n","user_id        0\n","dtype: int64"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["df_final.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oWwBSYldHBdd","executionInfo":{"status":"ok","timestamp":1695154972219,"user_tz":240,"elapsed":1152,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"a42e5ea0-a579-45d5-ae92-c3d5a0998167"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 740028 entries, 10 to 699006\n","Data columns (total 9 columns):\n"," #   Column       Non-Null Count   Dtype  \n","---  ------       --------------   -----  \n"," 0   business_id  740028 non-null  object \n"," 1   cool         740028 non-null  int64  \n"," 2   date         740028 non-null  object \n"," 3   funny        740028 non-null  int64  \n"," 4   review_id    740028 non-null  object \n"," 5   stars        740028 non-null  float64\n"," 6   text         740028 non-null  object \n"," 7   useful       740028 non-null  int64  \n"," 8   user_id      740028 non-null  object \n","dtypes: float64(1), int64(3), object(5)\n","memory usage: 56.5+ MB\n"]}]},{"cell_type":"code","source":["df_final.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"72j2QPV-HF90","executionInfo":{"status":"ok","timestamp":1695154990174,"user_tz":240,"elapsed":354,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"f967920b-0285-4cee-e65f-d7b461af514e"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                cool          funny          stars         useful\n","count  740028.000000  740028.000000  740028.000000  740028.000000\n","mean        0.787593       0.478593       3.814880       1.500955\n","std         3.087402       2.350815       1.300026       3.761798\n","min        -1.000000      -1.000000       1.000000      -1.000000\n","25%         0.000000       0.000000       3.000000       0.000000\n","50%         0.000000       0.000000       4.000000       1.000000\n","75%         1.000000       0.000000       5.000000       2.000000\n","max       400.000000     375.000000       5.000000     400.000000"],"text/html":["\n","  <div id=\"df-d7342bef-b455-43ad-a1b6-f9c720653e8a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cool</th>\n","      <th>funny</th>\n","      <th>stars</th>\n","      <th>useful</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>740028.000000</td>\n","      <td>740028.000000</td>\n","      <td>740028.000000</td>\n","      <td>740028.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.787593</td>\n","      <td>0.478593</td>\n","      <td>3.814880</td>\n","      <td>1.500955</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>3.087402</td>\n","      <td>2.350815</td>\n","      <td>1.300026</td>\n","      <td>3.761798</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-1.000000</td>\n","      <td>-1.000000</td>\n","      <td>1.000000</td>\n","      <td>-1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>5.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>400.000000</td>\n","      <td>375.000000</td>\n","      <td>5.000000</td>\n","      <td>400.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7342bef-b455-43ad-a1b6-f9c720653e8a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d7342bef-b455-43ad-a1b6-f9c720653e8a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d7342bef-b455-43ad-a1b6-f9c720653e8a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f55bd8e2-83d9-41ec-b170-3adf6c4492b7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f55bd8e2-83d9-41ec-b170-3adf6c4492b7')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f55bd8e2-83d9-41ec-b170-3adf6c4492b7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["df_final.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"id":"1Ys0dr0fIwcp","executionInfo":{"status":"ok","timestamp":1695155438135,"user_tz":240,"elapsed":180,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"67521709-361e-471d-c492-548999499bc9"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               business_id  cool                 date  funny  \\\n","10  EpREWeEpmR8f1qLHzzF0AA     0  2016-01-23 18:12:09      0   \n","15  kkcQYuF3w5iHnHMf0EnRhQ     0  2015-03-05 18:04:58      0   \n","27  1ig2AJg8A08_XA3pFAMiRQ     0  2011-12-02 20:31:56      0   \n","29  kkcQYuF3w5iHnHMf0EnRhQ     1  2015-07-05 16:16:59      0   \n","46  d3v51cMiLdNvn0GevIQDeg     2  2013-12-08 19:39:36      1   \n","\n","                 review_id  stars  \\\n","10  Z3mRrLxEhr22QtQSt4qG4w    4.0   \n","15  U1VgfQ3CegUgX2GnS6OKUA    5.0   \n","27  A6C3IJz4dtc7w1L-RHm0fg    5.0   \n","29  ASNAFrUepIa2SM2IheAUUQ    5.0   \n","46  k1KU_3-QE81Nf9V_skbbyw    3.0   \n","\n","                                                 text  useful  \\\n","10  It's a great place to hang out for a few beers...       0   \n","15  When I venture into the city its usually in th...       4   \n","27  Best steak EVER!!!  Coffee cured filet is my f...       0   \n","29  Drove down from Fox Chase last weekend and was...       0   \n","46  Katy Perry, kissed a  girl and liked it. I had...       4   \n","\n","                   user_id  \n","10  Ue10CO74ub6AeTI8u7-RNw  \n","15  tg2NumE_Zfy8sObhnotRew  \n","27  cCljNhHrJkfMY2l-LxO6ZA  \n","29  NCnHoYvkZArEc2x_l5S1Sg  \n","46  bYENop4BuQepBjM1-BI3fA  "],"text/html":["\n","  <div id=\"df-70c414dd-a769-4180-ac02-d7c0d408a3c6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>cool</th>\n","      <th>date</th>\n","      <th>funny</th>\n","      <th>review_id</th>\n","      <th>stars</th>\n","      <th>text</th>\n","      <th>useful</th>\n","      <th>user_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10</th>\n","      <td>EpREWeEpmR8f1qLHzzF0AA</td>\n","      <td>0</td>\n","      <td>2016-01-23 18:12:09</td>\n","      <td>0</td>\n","      <td>Z3mRrLxEhr22QtQSt4qG4w</td>\n","      <td>4.0</td>\n","      <td>It's a great place to hang out for a few beers...</td>\n","      <td>0</td>\n","      <td>Ue10CO74ub6AeTI8u7-RNw</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>kkcQYuF3w5iHnHMf0EnRhQ</td>\n","      <td>0</td>\n","      <td>2015-03-05 18:04:58</td>\n","      <td>0</td>\n","      <td>U1VgfQ3CegUgX2GnS6OKUA</td>\n","      <td>5.0</td>\n","      <td>When I venture into the city its usually in th...</td>\n","      <td>4</td>\n","      <td>tg2NumE_Zfy8sObhnotRew</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>1ig2AJg8A08_XA3pFAMiRQ</td>\n","      <td>0</td>\n","      <td>2011-12-02 20:31:56</td>\n","      <td>0</td>\n","      <td>A6C3IJz4dtc7w1L-RHm0fg</td>\n","      <td>5.0</td>\n","      <td>Best steak EVER!!!  Coffee cured filet is my f...</td>\n","      <td>0</td>\n","      <td>cCljNhHrJkfMY2l-LxO6ZA</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>kkcQYuF3w5iHnHMf0EnRhQ</td>\n","      <td>1</td>\n","      <td>2015-07-05 16:16:59</td>\n","      <td>0</td>\n","      <td>ASNAFrUepIa2SM2IheAUUQ</td>\n","      <td>5.0</td>\n","      <td>Drove down from Fox Chase last weekend and was...</td>\n","      <td>0</td>\n","      <td>NCnHoYvkZArEc2x_l5S1Sg</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>d3v51cMiLdNvn0GevIQDeg</td>\n","      <td>2</td>\n","      <td>2013-12-08 19:39:36</td>\n","      <td>1</td>\n","      <td>k1KU_3-QE81Nf9V_skbbyw</td>\n","      <td>3.0</td>\n","      <td>Katy Perry, kissed a  girl and liked it. I had...</td>\n","      <td>4</td>\n","      <td>bYENop4BuQepBjM1-BI3fA</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70c414dd-a769-4180-ac02-d7c0d408a3c6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-70c414dd-a769-4180-ac02-d7c0d408a3c6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-70c414dd-a769-4180-ac02-d7c0d408a3c6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2985de95-c6fd-424c-9cf8-97bf9f513843\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2985de95-c6fd-424c-9cf8-97bf9f513843')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2985de95-c6fd-424c-9cf8-97bf9f513843 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["Ver cantidad de negocios y cantidad de usuarios"],"metadata":{"id":"Bg8Cniu4HOff"}},{"cell_type":"code","source":["cantidad_negocios = df_final['business_id'].nunique()\n","\n","print(\"Cantidad de negocios:\", cantidad_negocios)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJqwCZ4eHRwk","executionInfo":{"status":"ok","timestamp":1695155038253,"user_tz":240,"elapsed":184,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"9944ac5e-40d3-45d2-fd3d-caeefabf2704"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Cantidad de negocios: 51379\n"]}]},{"cell_type":"code","source":["cantidad_usuarios = df_final['user_id'].nunique()\n","\n","print(\"Cantidad de usuarios:\", cantidad_usuarios)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x9Ilo051HVCF","executionInfo":{"status":"ok","timestamp":1695155051854,"user_tz":240,"elapsed":609,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"c42d5aa1-3748-4d9d-e17f-e7a708f079ff"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Cantidad de usuarios: 340828\n"]}]},{"cell_type":"markdown","source":["Los outliers segun la columna \"useful\" y \"cool\" pueden brindar informacion relevante segun los usuarios"],"metadata":{"id":"ckxUwr6pHZnM"}},{"cell_type":"code","source":["mean = df_final['useful'].mean()\n","std = df_final['useful'].std()\n","\n","threshold = 3 * std\n","outliers = (df_final['useful'] < (mean - threshold)) | (df_final['useful'] > (mean + threshold))\n","\n","outliers_useful = df_final[outliers]\n","outliers_useful.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_BibbH79Hbfe","executionInfo":{"status":"ok","timestamp":1695155086325,"user_tz":240,"elapsed":261,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"95dfc42d-4610-4708-f36e-9c94775f3671"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8841, 9)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["mean = df_final['cool'].mean()\n","std = df_final['cool'].std()\n","\n","threshold = 3 * std\n","outliers = (df_final['cool'] < (mean - threshold)) | (df_final['cool'] > (mean + threshold))\n","\n","outliers_cool = df_final[outliers]\n","outliers_cool.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKlpSMBBHjho","executionInfo":{"status":"ok","timestamp":1695155110981,"user_tz":240,"elapsed":8,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"a1f607ea-c600-4a3e-ab47-9a9fed8cf313"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6778, 9)"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["Consultar los business_id con mas cantidad de reseñas"],"metadata":{"id":"NnWhIMfUHvFW"}},{"cell_type":"code","source":["\n","resenas_por_business = df_final.groupby('business_id').size().reset_index(name='num_reseñas')\n","\n","# Ordenar los 'business_id' por cantidad de reseñas en orden descendente\n","resenas_por_business = resenas_por_business.sort_values('num_reseñas', ascending=False)\n","\n","# Tomar los 20 primeros 'business_id' con mayor cantidad de reseñas\n","top_20_business = resenas_por_business.head(20)\n","\n","# Mostrar los 20 business_id con más reseñas en un DataFrame\n","print(top_20_business)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"openUi8oH4U7","executionInfo":{"status":"ok","timestamp":1695155248267,"user_tz":240,"elapsed":408,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"c40f5352-05b8-49c0-855d-25d27a425c98"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["                  business_id  num_reseñas\n","21080  PP3BBaVxZLcJU54uP_wL6Q         3595\n","15797  IkY2ticzHEn4QFn8hQLSWg         2859\n","22689  RQAF6a0akMiot5lZZnMNNw         2435\n","45255  sTPueJEwcRDj7ZJmG7okYA         2430\n","33537  dsfRniRgfbDjC8os848B6A         1913\n","43280  q-zV08jt6U-q05SMEuQJAQ         1690\n","50493  ytynqOUb3hjKeJfRj5Tshw         1580\n","15615  IWHdx0NhDKADkGOgXgOFKQ         1562\n","652    -mIlmp5l4hKlp1tvHRdvTg         1492\n","17919  LM54ufrINJWoTN5imV8Etw         1425\n","22887  ReV4Q3rEJ8neicQPc6pC0w         1336\n","35642  gTC8IQ_i8zXytWSly3Ttvg         1134\n","32226  cGX-1IUwXOjkUqZbkKYcjw         1128\n","38442  jxEMFqwDJXjCxmcm5t5jVQ         1127\n","15668  I_3LMZ_1m2mzR0oLIOePIg         1120\n","41590  ntiIq1FNqduOyyowMFGh5A         1094\n","6207   6a4gLLFSgr-Q6CZXDLzBGQ         1012\n","37276  iSRTaT9WngzB8JJ2YKJUig          890\n","1528   0oSSjekU-3GR8gselReWnA          865\n","24471  TcNZXteosegb1RO4O5hREw          856\n"]}]},{"cell_type":"markdown","source":["Consultar los usuarios que han escritos mas reseñas"],"metadata":{"id":"5UfPX1q5ISr-"}},{"cell_type":"code","source":["conteo_reseñas_por_usuario = df_final.groupby('user_id').size()\n","\n","# Ordenar en orden descendente y seleccionar los 20 usuarios con más reseñas\n","usuarios_mas_reseñas = conteo_reseñas_por_usuario.nlargest(20)\n","\n","# Imprimir los 20 usuarios con más reseñas\n","print(usuarios_mas_reseñas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Jx3Fv-VIHB5","executionInfo":{"status":"ok","timestamp":1695155302647,"user_tz":240,"elapsed":2449,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"af186c0d-050b-434e-e683-f09f22521252"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["user_id\n","vmUqcqMjlWoBM6qfmUXgyQ    739\n","fr1Hz2acAb3OaL3l6DyKNg    635\n","-G7Zkl1wIWBBmD0KRy_sCw    493\n","AaJ9d4OrFmgc4S_U2QiSZg    419\n","bYENop4BuQepBjM1-BI3fA    411\n","wXdbkFZsfDR7utJvbWElyA    406\n","ouODopBKF3AqfCkuQEnrDg    396\n","eTvp_hYnsrI5-ow_sQ31_g    335\n","_BcWyKQL16ndpBdggh2kNA    319\n","VL12EhEdT4OWqGq0nIqkzw    316\n","qjfMBIZpQT9DDtw_BWCopQ    307\n","vffKQc_WQMYFGY4JS5VAOw    307\n","8VNmuYmFboXleIFf-stnFg    306\n","pou3BbKsIozfH50rxmnMew    306\n","vHc-UrI9yfL_pnnc6nJtyQ    291\n","1HM81n6n4iPIFU5d2Lokhw    282\n","zYFGMy1_thjMnvQLX6JNBw    271\n","ET8n-r7glWYqZhuR6GcdNw    269\n","kO30XR2WeF6bla6dK1ZZLw    255\n","Xw7ZjaGfr0WNVt6s_5KZfA    249\n","dtype: int64\n"]}]},{"cell_type":"markdown","source":["Comportamiento de los usuarios. Grafico de las horas en que se realizan mas reseñas"],"metadata":{"id":"lqYTKX-0JB5X"}},{"cell_type":"code","source":["df_final['date'] = pd.to_datetime(df_final['date'])\n","\n","# Obtener la hora para cada fecha\n","df_final['hora'] = df_final['date'].dt.hour\n","\n","# Contar la cantidad de reseñas por hora\n","resenas_por_hora = df_final['hora'].value_counts().sort_index()\n","\n","# Crear el gráfico de barras\n","plt.figure(figsize=(12, 6))\n","resenas_por_hora.plot(kind='bar', color='blue')\n","plt.xlabel('Hora del día')\n","plt.ylabel('Cantidad de reseñas')\n","plt.title('Cantidad de reseñas por hora del día')\n","plt.xticks(rotation=0)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":792},"id":"8f3B-Yy4I1sT","executionInfo":{"status":"ok","timestamp":1695155565503,"user_tz":240,"elapsed":806,"user":{"displayName":"Betzaida Loyo","userId":"11561215648091064361"}},"outputId":"c9be5e6a-f645-47ac-9b2e-599b2df48e98"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-32-52606263a07c>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_final['date'] = pd.to_datetime(df_final['date'])\n","<ipython-input-32-52606263a07c>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_final['hora'] = df_final['date'].dt.hour\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## **3. User**"],"metadata":{"id":"en7ZxZAIpiF4"}},{"cell_type":"code","source":[],"metadata":{"id":"LqfAsnIb2Nnd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **4. Checkin**"],"metadata":{"id":"80jLjZkjqsIt"}},{"cell_type":"code","source":["# Leemos el documento \"chekin\" en formato json.\n","chekin = pd.read_json('/content/drive/MyDrive/Final Project /Yelp/checkin.json', lines=True)\n","\n","# Observamos el dataframe \"chekin\" con las columnas y los datos que contienen.\n","chekin.sample(5)"],"metadata":{"id":"CXIHK2odoeDP","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"c9971f4e-8198-4147-ec14-bc6326aaa845"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   business_id  \\\n","113552  r9h2tC9eSpgWAbp7hw1QvA   \n","113979  rMqWPcEwfnUZ-f8coYHEsA   \n","88788   f8gfe7S-T15ll2sMURVeqg   \n","65224   UhA77Rfgcm46B7pUDCVh4g   \n","86501   e2xecLS4kmy87QdA0QI-Ew   \n","\n","                                                     date  \n","113552  2017-01-16 17:27:50, 2017-01-20 20:18:27, 2017...  \n","113979                                2012-05-18 14:09:04  \n","88788   2016-08-03 15:04:48, 2016-11-15 20:04:44, 2016...  \n","65224   2020-08-31 21:03:38, 2020-08-31 23:22:32, 2020...  \n","86501                                 2016-06-09 00:21:48  "],"text/html":["\n","  <div id=\"df-5a9c4a2f-059d-46e5-b9e6-310b569ee2ec\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>113552</th>\n","      <td>r9h2tC9eSpgWAbp7hw1QvA</td>\n","      <td>2017-01-16 17:27:50, 2017-01-20 20:18:27, 2017...</td>\n","    </tr>\n","    <tr>\n","      <th>113979</th>\n","      <td>rMqWPcEwfnUZ-f8coYHEsA</td>\n","      <td>2012-05-18 14:09:04</td>\n","    </tr>\n","    <tr>\n","      <th>88788</th>\n","      <td>f8gfe7S-T15ll2sMURVeqg</td>\n","      <td>2016-08-03 15:04:48, 2016-11-15 20:04:44, 2016...</td>\n","    </tr>\n","    <tr>\n","      <th>65224</th>\n","      <td>UhA77Rfgcm46B7pUDCVh4g</td>\n","      <td>2020-08-31 21:03:38, 2020-08-31 23:22:32, 2020...</td>\n","    </tr>\n","    <tr>\n","      <th>86501</th>\n","      <td>e2xecLS4kmy87QdA0QI-Ew</td>\n","      <td>2016-06-09 00:21:48</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a9c4a2f-059d-46e5-b9e6-310b569ee2ec')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5a9c4a2f-059d-46e5-b9e6-310b569ee2ec button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5a9c4a2f-059d-46e5-b9e6-310b569ee2ec');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5764c79c-610b-4b29-b6b8-b51cfb252b2d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5764c79c-610b-4b29-b6b8-b51cfb252b2d')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5764c79c-610b-4b29-b6b8-b51cfb252b2d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Obtenemos la información del dataframe como los nombres de las columnas, los valores totales, si cuentan con nulos y los tipos de datos.\n","chekin.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mk9zFL4HIniU","outputId":"801235d0-ad8a-476e-db56-3d6e585b5a35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 131930 entries, 0 to 131929\n","Data columns (total 2 columns):\n"," #   Column       Non-Null Count   Dtype \n","---  ------       --------------   ----- \n"," 0   business_id  131930 non-null  object\n"," 1   date         131930 non-null  object\n","dtypes: object(2)\n","memory usage: 2.0+ MB\n"]}]},{"cell_type":"markdown","source":["##**Comentarios:**\n","El dataframe cuenta con dos columnas, \"business_id\" y \"date\". Las fechas están conjuntas separadas en comas en formato object. Por lo que se realizará un EDA en donde podremos observer el ID con más fechas separadas y el ID con fecha más antigua y con la fecha más nueva."],"metadata":{"id":"7ldMu_9_IpoX"}},{"cell_type":"markdown","source":["4.1. ID con más fechas separadas"],"metadata":{"id":"Luumo-fUIsal"}},{"cell_type":"code","source":["# Creamos una función para contar las fechas de la columna \"date\".\n","def contar_fechas(fila):\n","    # Dividimos la cadena en fechas usando la coma como separador y contamos los elementos.\n","    fechas = fila.split(', ')\n","    return len(fechas)\n","\n","# Aplicamos la función a la columna \"date\" y creamos una nueva columna 'cantidad_fechas'\n","chekin['cantidad_fechas'] = chekin['date'].apply(contar_fechas)\n","\n","# Observamos los cambios en el dataframe.\n","chekin.sample(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"-QBV8WOSI01r","outputId":"caba9209-b76f-43f9-cb83-a0d8132bc970"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   business_id  \\\n","80759   bGPP22tfSHkc5OkYARGZBA   \n","45384   L1HNEw8NOWGGH3Uyttns4A   \n","124505  wRMdz34j57AUAQc28v9-hQ   \n","114901  rqD6cyApke-O-SkppUogTg   \n","106461  nl33PVk5w9JIqOlEGPS_ZA   \n","\n","                                                     date  cantidad_fechas  \n","80759   2010-06-12 17:31:49, 2010-06-12 21:32:41, 2011...              120  \n","45384   2010-11-27 02:51:15, 2011-04-23 21:50:25, 2011...               47  \n","124505  2010-07-10 01:14:53, 2010-08-08 00:50:41, 2010...             1855  \n","114901  2010-01-23 15:58:06, 2010-03-27 14:46:02, 2011...               39  \n","106461  2011-01-09 16:09:26, 2011-04-02 01:56:52, 2011...               26  "],"text/html":["\n","  <div id=\"df-10711dc7-c351-408f-be93-65098e96802b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>date</th>\n","      <th>cantidad_fechas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>80759</th>\n","      <td>bGPP22tfSHkc5OkYARGZBA</td>\n","      <td>2010-06-12 17:31:49, 2010-06-12 21:32:41, 2011...</td>\n","      <td>120</td>\n","    </tr>\n","    <tr>\n","      <th>45384</th>\n","      <td>L1HNEw8NOWGGH3Uyttns4A</td>\n","      <td>2010-11-27 02:51:15, 2011-04-23 21:50:25, 2011...</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>124505</th>\n","      <td>wRMdz34j57AUAQc28v9-hQ</td>\n","      <td>2010-07-10 01:14:53, 2010-08-08 00:50:41, 2010...</td>\n","      <td>1855</td>\n","    </tr>\n","    <tr>\n","      <th>114901</th>\n","      <td>rqD6cyApke-O-SkppUogTg</td>\n","      <td>2010-01-23 15:58:06, 2010-03-27 14:46:02, 2011...</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>106461</th>\n","      <td>nl33PVk5w9JIqOlEGPS_ZA</td>\n","      <td>2011-01-09 16:09:26, 2011-04-02 01:56:52, 2011...</td>\n","      <td>26</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10711dc7-c351-408f-be93-65098e96802b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-10711dc7-c351-408f-be93-65098e96802b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-10711dc7-c351-408f-be93-65098e96802b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d002721b-1084-4b7b-aadf-1d2b8f9028b2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d002721b-1084-4b7b-aadf-1d2b8f9028b2')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d002721b-1084-4b7b-aadf-1d2b8f9028b2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Encontramos el ID con la cantidad máxima de fechas.\n","id_max_fechas = chekin.loc[chekin['cantidad_fechas'].idxmax()]['business_id']\n","\n","# Observamos el id que tiene la cantidad máxima de fechas.\n","id_max_fechas"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"l7aa50HpI242","outputId":"629001ae-783f-4341-e17b-b504d7209611"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'-QI8Qi8XWH3D8y8ethnajA'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["4.2. ID's con fechas antiguas y fechas recientes"],"metadata":{"id":"4MHOkDfhI4nb"}},{"cell_type":"code","source":["# Dividimos las fechas en una columna por comas.\n","chekin['fechas'] = chekin['date'].str.split(',')\n","\n","# Duplicamos las filas para cada fecha con su respectivo ID.\n","chekin=chekin.explode('fechas').reset_index(drop=True)\n","\n","# Eliminamos la columna original.\n","chekin.drop('date',axis=1,inplace=True)\n","\n","# Observamos los cambios en el dataframe.\n","chekin.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Y1Ami_0rI7JU","outputId":"72beeda5-8383-400e-f5ec-2fd5f2315b08"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              business_id  cantidad_fechas                fechas\n","0  ---kPU91CF4Lq2-WlRu9Lw               11   2020-03-13 21:10:56\n","1  ---kPU91CF4Lq2-WlRu9Lw               11   2020-06-02 22:18:06\n","2  ---kPU91CF4Lq2-WlRu9Lw               11   2020-07-24 22:42:27\n","3  ---kPU91CF4Lq2-WlRu9Lw               11   2020-10-24 21:36:13\n","4  ---kPU91CF4Lq2-WlRu9Lw               11   2020-12-09 21:23:33"],"text/html":["\n","  <div id=\"df-719c59db-1daa-4b18-97da-73f462630c23\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>cantidad_fechas</th>\n","      <th>fechas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n","      <td>11</td>\n","      <td>2020-03-13 21:10:56</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n","      <td>11</td>\n","      <td>2020-06-02 22:18:06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n","      <td>11</td>\n","      <td>2020-07-24 22:42:27</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n","      <td>11</td>\n","      <td>2020-10-24 21:36:13</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n","      <td>11</td>\n","      <td>2020-12-09 21:23:33</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-719c59db-1daa-4b18-97da-73f462630c23')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-719c59db-1daa-4b18-97da-73f462630c23 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-719c59db-1daa-4b18-97da-73f462630c23');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-77657a79-2ea5-4f32-9e26-1fba50eb2c32\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77657a79-2ea5-4f32-9e26-1fba50eb2c32')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-77657a79-2ea5-4f32-9e26-1fba50eb2c32 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# Buscamos el ID con la fecha más antigua.\n","fecha_minima = chekin['fechas'].min()\n","id_fecha_minima = chekin.loc[chekin['fechas'] == fecha_minima]\n","id_fecha_minima"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"ihBTFVdHI8sy","outputId":"5d82344b-d25a-4534-8499-f2853b499262"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    business_id  cantidad_fechas                fechas\n","8511938  cFk2SMsJ-2cmXKLFFkP9JA              587   2010-01-17 02:15:25"],"text/html":["\n","  <div id=\"df-1c252119-3f3b-41c8-97a5-462e609fed27\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>cantidad_fechas</th>\n","      <th>fechas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8511938</th>\n","      <td>cFk2SMsJ-2cmXKLFFkP9JA</td>\n","      <td>587</td>\n","      <td>2010-01-17 02:15:25</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c252119-3f3b-41c8-97a5-462e609fed27')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1c252119-3f3b-41c8-97a5-462e609fed27 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1c252119-3f3b-41c8-97a5-462e609fed27');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Buscamos el ID con la fecha más reciente.\n","fecha_maxima = chekin['fechas'].max()\n","id_fecha_maxima = chekin.loc[chekin['fechas'] == fecha_maxima]\n","id_fecha_maxima"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"_Bn6ntaII-F9","outputId":"3d4bce3f-e13e-4d40-eaf4-e09f774790c0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    business_id  cantidad_fechas               fechas\n","3188598  DjpCcVUuolhT6FF78W1aQw                1  2022-01-19 01:15:21"],"text/html":["\n","  <div id=\"df-cf92f5b1-84ff-4fb8-8107-36a3dab58b98\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>cantidad_fechas</th>\n","      <th>fechas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3188598</th>\n","      <td>DjpCcVUuolhT6FF78W1aQw</td>\n","      <td>1</td>\n","      <td>2022-01-19 01:15:21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf92f5b1-84ff-4fb8-8107-36a3dab58b98')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cf92f5b1-84ff-4fb8-8107-36a3dab58b98 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cf92f5b1-84ff-4fb8-8107-36a3dab58b98');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# Transformamos la columna \"fechas\" en el formato datetime \"aaaa-mm-dd\".\n","chekin['fechas'] = pd.to_datetime(chekin['fechas'],  errors='coerce').dt.strftime('%Y-%m-%d')\n","chekin.sample(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"2j0l5qOyJAM9","outputId":"8e4b64c0-e14b-4219-bdf6-7bb61782dc01"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     business_id  cantidad_fechas      fechas\n","7352668   Xdy7tkuV0ViNFVxcsL4wjA              126  2021-06-05\n","310509    06pNHtxgPhGhZpM0Z2uzNw             2364  2016-10-14\n","548544    1KpNlu8VM8ukw3uOzmMFPA             1042  2013-05-12\n","8158360   abvsCLYEOvhsWSlgiTvbCQ               90  2018-12-19\n","11385795  q6hWVlVeiCgMgM22wt1wfw             2326  2015-04-18"],"text/html":["\n","  <div id=\"df-704d4182-284b-44c6-bfec-d82f2314fd6f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>cantidad_fechas</th>\n","      <th>fechas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7352668</th>\n","      <td>Xdy7tkuV0ViNFVxcsL4wjA</td>\n","      <td>126</td>\n","      <td>2021-06-05</td>\n","    </tr>\n","    <tr>\n","      <th>310509</th>\n","      <td>06pNHtxgPhGhZpM0Z2uzNw</td>\n","      <td>2364</td>\n","      <td>2016-10-14</td>\n","    </tr>\n","    <tr>\n","      <th>548544</th>\n","      <td>1KpNlu8VM8ukw3uOzmMFPA</td>\n","      <td>1042</td>\n","      <td>2013-05-12</td>\n","    </tr>\n","    <tr>\n","      <th>8158360</th>\n","      <td>abvsCLYEOvhsWSlgiTvbCQ</td>\n","      <td>90</td>\n","      <td>2018-12-19</td>\n","    </tr>\n","    <tr>\n","      <th>11385795</th>\n","      <td>q6hWVlVeiCgMgM22wt1wfw</td>\n","      <td>2326</td>\n","      <td>2015-04-18</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-704d4182-284b-44c6-bfec-d82f2314fd6f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-704d4182-284b-44c6-bfec-d82f2314fd6f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-704d4182-284b-44c6-bfec-d82f2314fd6f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d7ae3d6e-300c-4381-9e3a-159ee07d0ac1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7ae3d6e-300c-4381-9e3a-159ee07d0ac1')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d7ae3d6e-300c-4381-9e3a-159ee07d0ac1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## **5. Tip**"],"metadata":{"id":"nETPNGZArkdB"}},{"cell_type":"code","source":[],"metadata":{"id":"e1K51Dk2oeTc"},"execution_count":null,"outputs":[]}]}
